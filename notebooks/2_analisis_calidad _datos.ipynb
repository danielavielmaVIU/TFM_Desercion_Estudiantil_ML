{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30073cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Obtener ruta absoluta \n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.append(PROJECT_ROOT)\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "from src.data.clean_columns import clean_dataframe_columns\n",
    "from src.utils.constants import(\n",
    "    VARS_BINARIAS,\n",
    "    VARS_CATEGORICAS_NOMINALES,\n",
    "    VARS_CATEGORICAS_ORDINALES,\n",
    "    VARS_NUMERICAS,\n",
    "    TARGET,\n",
    "    TARGET_VALUES,\n",
    "    LABELS    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f557441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar dataset\n",
    "df = pd.read_csv('../data/raw/data.csv', delimiter=';')\n",
    "df = clean_dataframe_columns(df)\n",
    "\n",
    "print(\"Dataset cargado correctamente\\n\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd423938",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"==============================================================\")\n",
    "print(\"1. DIMENSIÓN DEL DATASET\")\n",
    "print(\"==============================================================\")\n",
    "print(f\"Filas: {df.shape[0]}\")\n",
    "print(f\"Columnas: {df.shape[1]}\")\n",
    "print(f\"Celdas totales: {df.shape[0] * df.shape[1]:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd8a532",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"==============================================================\")\n",
    "print(\"2. COMPLETITUD - Valores Nulos\")\n",
    "print(\"==============================================================\")\n",
    "\n",
    "nulls = df.isnull().sum()\n",
    "nulls_pct = (nulls / len(df)) * 100\n",
    "\n",
    "tabla_nulos = pd.DataFrame({\n",
    "    \"nulos\": nulls,\n",
    "    \"% nulos\": nulls_pct.round(2)\n",
    "})\n",
    "\n",
    "display(tabla_nulos)\n",
    "\n",
    "print(\"\\nTotal de valores nulos en dataset:\", nulls.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce73dcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"==============================================================\")\n",
    "print(\"3. CONSISTENCIA - Duplicados\")\n",
    "print(\"==============================================================\")\n",
    "\n",
    "duplicates = df.duplicated().sum()\n",
    "pct_dup = duplicates / len(df) * 100\n",
    "\n",
    "print(f\"Porcentaje de filas duplicadas: {pct_dup:.2f}%\")\n",
    "\n",
    "print(f\"\\nRegistros duplicados: {duplicates}\")\n",
    "\n",
    "if duplicates > 0:\n",
    "    display(df[df.duplicated()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b138f0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"==============================================================\")\n",
    "print(\"3. CONSISTENCIA - Distribuciones Sesgadas\")\n",
    "print(\"==============================================================\")\n",
    "\n",
    "\"\"\"\n",
    "    Calcula un puntaje de calidad basado en la distribución estadística de una variable numérica, utilizando medidas de asimetría (skewness) y curtosis (kurtosis).\n",
    "\n",
    "    El objetivo del puntaje es evaluar qué tan \"normal\" o equilibrada es la distribución de la variable. Las distribuciones altamente sesgadas o con colas pesadas reciben penalizaciones, dado que pueden afectar \n",
    "    negativamente los modelos de machine learning.\n",
    "\n",
    "    Parámetros\n",
    "    ----------\n",
    "    col : str\n",
    "        Nombre de la columna del DataFrame (df) a evaluar.\n",
    "\n",
    "    Lógica de Cálculo\n",
    "    -----------------\n",
    "    1. Se calcula la asimetría absoluta (skewness):\n",
    "         - Penalización: skew * 10\n",
    "         - Penalización máxima a aplicar 40 puntos\n",
    "\n",
    "    2. Se calcula la curtosis absoluta (kurtosis):\n",
    "         - Penalización: kurt * 5\n",
    "         - Penalización máxima a aplica 40 puntos\n",
    "\n",
    "    3. Se parte de un puntaje base de 100 y se restan las penalizaciones.\n",
    "\n",
    "    4. El puntaje final se trunca en 0 para evitar valores negativos.\n",
    "\n",
    "    Retorna\n",
    "    -------\n",
    "    int\n",
    "        Puntaje de calidad entre 0 y 100, donde:\n",
    "            - 100 indica distribución ideal (similar a normal)\n",
    "            - 70-90 indica distribución aceptable\n",
    "            - 40-70 sugiere problemas de asimetría o colas pesadas\n",
    "            - < 40 indica distribución crítica y posiblemente distorsionada\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "def score_distribucion(col):\n",
    "\n",
    "    \n",
    "    skew = abs(df[col].skew())\n",
    "    kurt = abs(df[col].kurtosis())\n",
    "\n",
    "    score = 100\n",
    "\n",
    "    score -= min(skew * 10, 40)     # penalización por skew\n",
    "    score -= min(kurt * 5, 40)      # penalización por curtosis\n",
    "\n",
    "    return max(score, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4b2e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"==============================================================\")\n",
    "print(\"3. CONSISTENCIA - Categorias no representativas\")\n",
    "print(\"==============================================================\")\n",
    "\n",
    "\"\"\"\n",
    "    Calcula un puntaje de calidad para variables categóricas basado\n",
    "    en la cantidad de categorías con baja frecuencia (\"categorías raras\").\n",
    "\n",
    "    Las categorías raras pueden generar inestabilidad en modelos predictivos,\n",
    "    especialmente cuando se aplica one-hot encoding o técnicas basadas en \n",
    "    frecuencias. Este puntaje permite evaluar el riesgo asociado a la baja \n",
    "    representatividad de ciertas categorías.\n",
    "\n",
    "    Parámetros\n",
    "    ----------\n",
    "    col : str\n",
    "        Nombre de la columna del DataFrame a evaluar.\n",
    "\n",
    "    umbral : int, opcional (default=10)\n",
    "        Número mínimo de observaciones requerido para que una categoría\n",
    "        sea considerada suficientemente representativa.\n",
    "        Las categorías con frecuencia < umbral son clasificadas como \"raras\".\n",
    "\n",
    "    Lógica de Cálculo\n",
    "    -----------------\n",
    "    1. Se contabiliza cuántas categorías tienen menos de `umbral` observaciones.\n",
    "    2. Se asigna un puntaje según la severidad del problema:\n",
    "\n",
    "        - 0 categorías raras     → Score = 100 (excelente)\n",
    "        - 1-2 categorías raras   → Score = 80 (riesgo bajo)\n",
    "        - 3-5 categorías raras   → Score = 60 (riesgo moderado)\n",
    "        - > 5 categorías raras    → Score = 30 (riesgo alto)\n",
    "\n",
    "    Retorna\n",
    "    -------\n",
    "    int\n",
    "        Puntaje de calidad entre 30 y 100:\n",
    "            - 100 indica que no existen categorías raras\n",
    "            - 80 indica leve riesgo\n",
    "            - 60 indica riesgo moderado por poca representatividad\n",
    "            - 30 indica riesgo severo para modelado\n",
    "    \"\"\"\n",
    "\n",
    "def score_categorias_raras(col, umbral=10):\n",
    "    conteos = df[col].value_counts()\n",
    "\n",
    "    n_raras = (conteos < umbral).sum()\n",
    "\n",
    "    if n_raras == 0:\n",
    "        return 100\n",
    "    elif n_raras <= 2:\n",
    "        return 80\n",
    "    elif n_raras <= 5:\n",
    "        return 60\n",
    "    else:\n",
    "        return 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aac1c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"==============================================================\")\n",
    "print(\"4. EXACTITUD - Validación de categorías fuera de dominio\")\n",
    "print(\"==============================================================\")\n",
    "\n",
    "errores_dominio = {}\n",
    "\n",
    "for col, mapping in LABELS.items():\n",
    "    valores_validos = set(mapping.keys())\n",
    "    valores_actuales = set(df[col].unique())\n",
    "    fuera = valores_actuales - valores_validos\n",
    "\n",
    "    if len(fuera) > 0:\n",
    "        errores_dominio[col] = list(fuera)\n",
    "errores_dominio\n",
    "\n",
    "# Calcula score \n",
    "score_dominio = {}\n",
    "for col in df.columns:\n",
    "    if col not in errores_dominio:\n",
    "        score_dominio[col] = 100\n",
    "    else:\n",
    "        n = len(errores_dominio[col])\n",
    "        score_dominio[col] = max(0, 100 - 20 * n)\n",
    "\n",
    "\n",
    "if len(errores_dominio) == 0:\n",
    "    print(\"\\nNo existen valores fuera del dominio definido.\")\n",
    "else:\n",
    "    print(\" Valores fuera de dominio encontrados:\")\n",
    "\n",
    "    rows = []\n",
    "    for variable, valores in errores_dominio.items():\n",
    "        for v in valores:\n",
    "            rows.append({\"Variable\": variable, \"Valor fuera de dominio\": v})\n",
    "\n",
    "    df_errores = pd.DataFrame(rows)\n",
    "    display(df_errores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb9994c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"==============================================================\")\n",
    "print(\"6. OUTLIERS - Método IQR\")\n",
    "print(\"==============================================================\")\n",
    "\n",
    "outlier_report = []\n",
    "\n",
    "numericas = df.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "\n",
    "for col in numericas:\n",
    "\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    lower = Q1 - 1.5 * IQR\n",
    "    upper = Q3 + 1.5 * IQR\n",
    "\n",
    "    n_outliers = ((df[col] < lower) | (df[col] > upper)).sum()\n",
    "    pct = round(n_outliers / len(df) * 100, 2)\n",
    "\n",
    "    outlier_report.append([col, n_outliers, pct])\n",
    "\n",
    "tabla_outliers = pd.DataFrame(outlier_report,columns=[\"Variable\", \"Outliers IQR\", \"% IQR\"])\n",
    "\n",
    "# Calcula score de rangos\n",
    "score_rangos = {}\n",
    "for _, row in tabla_outliers.iterrows():\n",
    "    score_rangos[row[\"Variable\"]] = max(0, 100 - row[\"% IQR\"] * 1.2)\n",
    "\n",
    "# Las no-numéricas reciben 100\n",
    "for col in df.columns:\n",
    "    score_rangos.setdefault(col, 100)\n",
    "\n",
    "display(tabla_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea2c23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"==============================================================\")\n",
    "print(\"7. EXACTITUD – Validación de tipos de datos\")\n",
    "print(\"==============================================================\")\n",
    "\n",
    "df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227e116e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"==============================================================\")\n",
    "print(\"8. ÍNDICE GLOBAL DE CALIDAD DEL DATASET\")\n",
    "print(\"==============================================================\")\n",
    "\n",
    "# Crear base del índice con todas las columnas del dataset\n",
    "metricas = pd.DataFrame(index=df.columns)\n",
    "\n",
    "#### Dimensión COMPLETITUD ####\n",
    "# --- 1. % NULOS ---\n",
    "metricas[\"Valores_nulos\"] = 100 - nulls_pct\n",
    "\n",
    "\n",
    "#### Dimensión CONSISTENCIA ####\n",
    "# --- 2. Duplicados ---\n",
    "metricas[\"Duplicados\"] = 100 - pct_dup\n",
    "\n",
    "# --- 3. % Distribuciones Sesgadas ---\n",
    "metricas[\"Score_sesgo\"] = [\n",
    "    score_distribucion(col) if col in VARS_NUMERICAS else np.nan\n",
    "    for col in df.columns\n",
    "]\n",
    "# --- 4. % Categorias no representativas ---\n",
    "metricas[\"Score_ategorías_raras\"] = [\n",
    "    score_categorias_raras(col) if col in VARS_CATEGORICAS_NOMINALES else np.nan\n",
    "    for col in df.columns\n",
    "]\n",
    "\n",
    "#### Dimensión EXACTITUD ####\n",
    "# --- 3. EXACTITUD ---\n",
    "metricas[\"Exactitud_dominio\"] = metricas.index.map(score_dominio)\n",
    "metricas[\"Exactitud_rangos\"] = metricas.index.map(score_rangos).round(2)\n",
    "\n",
    "metricas[\"Score Calidad\"] = (\n",
    "    0.1666 * metricas[\"Valores_nulos\"] +\n",
    "    0.1666 * metricas[\"Duplicados\"] +\n",
    "    0.1666 * metricas[\"Score_sesgo\"].fillna(100) +\n",
    "    0.1666 * metricas[\"Score_ategorías_raras\"].fillna(100) + \n",
    "    0.1666 * metricas[\"Exactitud_dominio\"] +\n",
    "    0.1666 * metricas[\"Exactitud_rangos\"] \n",
    ").round(2)\n",
    "\n",
    "metricas = metricas.round({\n",
    "    \"Valores_nulos\": 2,\n",
    "    \"Duplicados\": 2,\n",
    "    \"Score_sesgo\": 2,\n",
    "    \"Score_ategorías_raras\": 2,\n",
    "    \"Exactitud_dominio\": 2,\n",
    "    \"Exactitud_rangos\": 2, \n",
    "})\n",
    "\n",
    "def clasificar(score):\n",
    "    if score >= 90:\n",
    "        return \"Excelente\"\n",
    "    elif score >= 80:\n",
    "        return \"Muy Buena\"\n",
    "    elif score >= 70:\n",
    "        return \"Aceptable\"\n",
    "    elif score >= 60:\n",
    "        return \"Baja\"\n",
    "    else:\n",
    "        return \"Crítica\"\n",
    "\n",
    "metricas[\"Nivel Calidad\"] = metricas[\"Score Calidad\"].apply(clasificar)\n",
    "metricas_sorted = metricas.sort_values(\"Score Calidad\")\n",
    "metricas_sorted = metricas_sorted.sort_values(\"Score Calidad\")\n",
    "metricas_sorted.to_csv(\"../outputs/tables/indice_calidad_dataset.csv\", index=True)\n",
    "print(\"Tabla de índice de calidad guardada en outputs/tables\")\n",
    "\n",
    "display(metricas.sort_values(\"Score Calidad\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFM_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
