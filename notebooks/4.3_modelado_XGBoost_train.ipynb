{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# MODELADO XGBOOST (SIN OPTIMIZACIÓN)\n",
    "\n",
    "Objetivo: Entrenar modelo XGBoost con hiperparámetros por defecto para comparar con el baseline (Regresión Logística).\n",
    "\n",
    "Fases temporales:\n",
    "- T0 (Matrícula)          : Variables disponibles al momento de inscripción\n",
    "- T1 (Fin 1er Semestre)   : T0 + variables académicas del 1er semestre\n",
    "- T2 (Fin 2do Semestre)   : T1 + variables académicas del 2do semestre\n",
    "\n",
    "Preprocesamiento específico para XGBoost:\n",
    "- No requiere escalado\n",
    "- Label Encoding para categóricas\n",
    "- Target Encoding para 'course'\n",
    "\n",
    "Pipeline:\n",
    "1. Carga de datos preprocesados\n",
    "2. Definición de variables por fase temporal\n",
    "3. Split estratificado (80/20)\n",
    "4. Preprocesamiento específico para XGBoost\n",
    "5. Entrenamiento con Cross-Validation 5-fold\n",
    "6. Evaluación en test set\n",
    "7. Comparación de resultados por fase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-imports",
   "metadata": {},
   "source": [
    "## 0. Librerias y configuración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Preprocesamiento\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Modelo\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Métricas\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix, classification_report,\n",
    "    roc_curve, precision_recall_curve, average_precision_score\n",
    ")\n",
    "\n",
    "# Target Encoding\n",
    "from category_encoders import TargetEncoder\n",
    "\n",
    "# Configuración de visualización\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "\n",
    "# Seed para reproducibilidad\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# Directorio de salida\n",
    "OUTPUT_DIR = \"../outputs/figures/modelado/XGBoost/\"\n",
    "OUTPUT_DIR_REPORTES = \"../outputs/models/XGBoost/\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(OUTPUT_DIR_REPORTES, exist_ok=True)\n",
    "\n",
    "# mlflow\n",
    "import mlflow\n",
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-load",
   "metadata": {},
   "source": [
    "## 1. Carga de datos preprocesados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "load-data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cargado: 4424 filas x 38 columnas\n",
      "target_binario\n",
      "0    3003\n",
      "1    1421\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Ratio de desbalance: 2.11:1\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "application_order",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "course",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "daytimeevening_attendance",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "previous_qualification_grade",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "admission_grade",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "displaced",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "educational_special_needs",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "debtor",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "tuition_fees_up_to_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "gender",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "scholarship_holder",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "age_at_enrollment",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "international",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "curricular_units_1st_sem_credited",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "curricular_units_1st_sem_enrolled",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "curricular_units_1st_sem_evaluations",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "curricular_units_1st_sem_approved",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "curricular_units_1st_sem_grade",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "curricular_units_1st_sem_without_evaluations",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "curricular_units_2nd_sem_credited",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "curricular_units_2nd_sem_enrolled",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "curricular_units_2nd_sem_evaluations",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "curricular_units_2nd_sem_approved",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "curricular_units_2nd_sem_grade",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "curricular_units_2nd_sem_without_evaluations",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "unemployment_rate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "inflation_rate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "gdp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "is_single",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "application_mode_risk",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "is_over_23_entry",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "previous_qualification_risk",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "mothers_qualification_level",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "fathers_qualification_level",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "mothers_occupation_level",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "fathers_occupation_level",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "has_unknown_parent_info",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "target_binario",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "c6c81d1a-081f-4928-8d40-ec4e6e538927",
       "rows": [
        [
         "0",
         "5",
         "171",
         "1",
         "122.0",
         "127.3",
         "1",
         "0",
         "0",
         "1",
         "1",
         "0",
         "20",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0.0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0.0",
         "0",
         "10.8",
         "1.4",
         "1.74",
         "1",
         "Bajo_Riesgo",
         "0",
         "Bajo_Riesgo",
         "Basica_Media",
         "Secundaria",
         "Otro_Trabajo",
         "Otro_Trabajo",
         "0",
         "1"
        ],
        [
         "1",
         "1",
         "9254",
         "1",
         "160.0",
         "142.5",
         "1",
         "0",
         "0",
         "0",
         "1",
         "0",
         "19",
         "0",
         "0",
         "6",
         "6",
         "6",
         "14.0",
         "0",
         "0",
         "6",
         "6",
         "6",
         "13.666666666666666",
         "0",
         "13.9",
         "-0.3",
         "0.79",
         "1",
         "Bajo_Riesgo",
         "0",
         "Bajo_Riesgo",
         "Secundaria",
         "Superior",
         "Profesional",
         "Profesional",
         "0",
         "0"
        ],
        [
         "2",
         "5",
         "9070",
         "1",
         "122.0",
         "124.8",
         "1",
         "0",
         "0",
         "0",
         "1",
         "0",
         "19",
         "0",
         "0",
         "6",
         "0",
         "0",
         "0.0",
         "0",
         "0",
         "6",
         "0",
         "0",
         "0.0",
         "0",
         "10.8",
         "1.4",
         "1.74",
         "1",
         "Bajo_Riesgo",
         "0",
         "Bajo_Riesgo",
         "Basica_Baja",
         "Basica_Baja",
         "Otro_Trabajo",
         "Otro_Trabajo",
         "0",
         "1"
        ],
        [
         "3",
         "2",
         "9773",
         "1",
         "122.0",
         "119.6",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "20",
         "0",
         "0",
         "6",
         "8",
         "6",
         "13.428571428571429",
         "0",
         "0",
         "6",
         "10",
         "5",
         "12.4",
         "0",
         "9.4",
         "-0.8",
         "-3.12",
         "1",
         "Bajo_Riesgo",
         "0",
         "Bajo_Riesgo",
         "Basica_Media",
         "Basica_Baja",
         "Otro_Trabajo",
         "Profesional",
         "0",
         "0"
        ],
        [
         "4",
         "1",
         "8014",
         "0",
         "100.0",
         "141.5",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "45",
         "0",
         "0",
         "6",
         "9",
         "5",
         "12.333333333333334",
         "0",
         "0",
         "6",
         "6",
         "6",
         "13.0",
         "0",
         "13.9",
         "-0.3",
         "0.79",
         "0",
         "Alto_Riesgo",
         "1",
         "Bajo_Riesgo",
         "Basica_Baja",
         "Basica_Media",
         "Otro_Trabajo",
         "Otro_Trabajo",
         "0",
         "0"
        ]
       ],
       "shape": {
        "columns": 38,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>application_order</th>\n",
       "      <th>course</th>\n",
       "      <th>daytimeevening_attendance</th>\n",
       "      <th>previous_qualification_grade</th>\n",
       "      <th>admission_grade</th>\n",
       "      <th>displaced</th>\n",
       "      <th>educational_special_needs</th>\n",
       "      <th>debtor</th>\n",
       "      <th>tuition_fees_up_to_date</th>\n",
       "      <th>gender</th>\n",
       "      <th>scholarship_holder</th>\n",
       "      <th>age_at_enrollment</th>\n",
       "      <th>international</th>\n",
       "      <th>curricular_units_1st_sem_credited</th>\n",
       "      <th>curricular_units_1st_sem_enrolled</th>\n",
       "      <th>curricular_units_1st_sem_evaluations</th>\n",
       "      <th>curricular_units_1st_sem_approved</th>\n",
       "      <th>curricular_units_1st_sem_grade</th>\n",
       "      <th>curricular_units_1st_sem_without_evaluations</th>\n",
       "      <th>curricular_units_2nd_sem_credited</th>\n",
       "      <th>curricular_units_2nd_sem_enrolled</th>\n",
       "      <th>curricular_units_2nd_sem_evaluations</th>\n",
       "      <th>curricular_units_2nd_sem_approved</th>\n",
       "      <th>curricular_units_2nd_sem_grade</th>\n",
       "      <th>curricular_units_2nd_sem_without_evaluations</th>\n",
       "      <th>unemployment_rate</th>\n",
       "      <th>inflation_rate</th>\n",
       "      <th>gdp</th>\n",
       "      <th>is_single</th>\n",
       "      <th>application_mode_risk</th>\n",
       "      <th>is_over_23_entry</th>\n",
       "      <th>previous_qualification_risk</th>\n",
       "      <th>mothers_qualification_level</th>\n",
       "      <th>fathers_qualification_level</th>\n",
       "      <th>mothers_occupation_level</th>\n",
       "      <th>fathers_occupation_level</th>\n",
       "      <th>has_unknown_parent_info</th>\n",
       "      <th>target_binario</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>171</td>\n",
       "      <td>1</td>\n",
       "      <td>122.0000</td>\n",
       "      <td>127.3000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>10.8000</td>\n",
       "      <td>1.4000</td>\n",
       "      <td>1.7400</td>\n",
       "      <td>1</td>\n",
       "      <td>Bajo_Riesgo</td>\n",
       "      <td>0</td>\n",
       "      <td>Bajo_Riesgo</td>\n",
       "      <td>Basica_Media</td>\n",
       "      <td>Secundaria</td>\n",
       "      <td>Otro_Trabajo</td>\n",
       "      <td>Otro_Trabajo</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9254</td>\n",
       "      <td>1</td>\n",
       "      <td>160.0000</td>\n",
       "      <td>142.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>14.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>13.6667</td>\n",
       "      <td>0</td>\n",
       "      <td>13.9000</td>\n",
       "      <td>-0.3000</td>\n",
       "      <td>0.7900</td>\n",
       "      <td>1</td>\n",
       "      <td>Bajo_Riesgo</td>\n",
       "      <td>0</td>\n",
       "      <td>Bajo_Riesgo</td>\n",
       "      <td>Secundaria</td>\n",
       "      <td>Superior</td>\n",
       "      <td>Profesional</td>\n",
       "      <td>Profesional</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>9070</td>\n",
       "      <td>1</td>\n",
       "      <td>122.0000</td>\n",
       "      <td>124.8000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>10.8000</td>\n",
       "      <td>1.4000</td>\n",
       "      <td>1.7400</td>\n",
       "      <td>1</td>\n",
       "      <td>Bajo_Riesgo</td>\n",
       "      <td>0</td>\n",
       "      <td>Bajo_Riesgo</td>\n",
       "      <td>Basica_Baja</td>\n",
       "      <td>Basica_Baja</td>\n",
       "      <td>Otro_Trabajo</td>\n",
       "      <td>Otro_Trabajo</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>9773</td>\n",
       "      <td>1</td>\n",
       "      <td>122.0000</td>\n",
       "      <td>119.6000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>13.4286</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>12.4000</td>\n",
       "      <td>0</td>\n",
       "      <td>9.4000</td>\n",
       "      <td>-0.8000</td>\n",
       "      <td>-3.1200</td>\n",
       "      <td>1</td>\n",
       "      <td>Bajo_Riesgo</td>\n",
       "      <td>0</td>\n",
       "      <td>Bajo_Riesgo</td>\n",
       "      <td>Basica_Media</td>\n",
       "      <td>Basica_Baja</td>\n",
       "      <td>Otro_Trabajo</td>\n",
       "      <td>Profesional</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>8014</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>141.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>12.3333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>13.9000</td>\n",
       "      <td>-0.3000</td>\n",
       "      <td>0.7900</td>\n",
       "      <td>0</td>\n",
       "      <td>Alto_Riesgo</td>\n",
       "      <td>1</td>\n",
       "      <td>Bajo_Riesgo</td>\n",
       "      <td>Basica_Baja</td>\n",
       "      <td>Basica_Media</td>\n",
       "      <td>Otro_Trabajo</td>\n",
       "      <td>Otro_Trabajo</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   application_order  course  daytimeevening_attendance  \\\n",
       "0                  5     171                          1   \n",
       "1                  1    9254                          1   \n",
       "2                  5    9070                          1   \n",
       "3                  2    9773                          1   \n",
       "4                  1    8014                          0   \n",
       "\n",
       "   previous_qualification_grade  admission_grade  displaced  \\\n",
       "0                      122.0000         127.3000          1   \n",
       "1                      160.0000         142.5000          1   \n",
       "2                      122.0000         124.8000          1   \n",
       "3                      122.0000         119.6000          1   \n",
       "4                      100.0000         141.5000          0   \n",
       "\n",
       "   educational_special_needs  debtor  tuition_fees_up_to_date  gender  \\\n",
       "0                          0       0                        1       1   \n",
       "1                          0       0                        0       1   \n",
       "2                          0       0                        0       1   \n",
       "3                          0       0                        1       0   \n",
       "4                          0       0                        1       0   \n",
       "\n",
       "   scholarship_holder  age_at_enrollment  international  \\\n",
       "0                   0                 20              0   \n",
       "1                   0                 19              0   \n",
       "2                   0                 19              0   \n",
       "3                   0                 20              0   \n",
       "4                   0                 45              0   \n",
       "\n",
       "   curricular_units_1st_sem_credited  curricular_units_1st_sem_enrolled  \\\n",
       "0                                  0                                  0   \n",
       "1                                  0                                  6   \n",
       "2                                  0                                  6   \n",
       "3                                  0                                  6   \n",
       "4                                  0                                  6   \n",
       "\n",
       "   curricular_units_1st_sem_evaluations  curricular_units_1st_sem_approved  \\\n",
       "0                                     0                                  0   \n",
       "1                                     6                                  6   \n",
       "2                                     0                                  0   \n",
       "3                                     8                                  6   \n",
       "4                                     9                                  5   \n",
       "\n",
       "   curricular_units_1st_sem_grade  \\\n",
       "0                          0.0000   \n",
       "1                         14.0000   \n",
       "2                          0.0000   \n",
       "3                         13.4286   \n",
       "4                         12.3333   \n",
       "\n",
       "   curricular_units_1st_sem_without_evaluations  \\\n",
       "0                                             0   \n",
       "1                                             0   \n",
       "2                                             0   \n",
       "3                                             0   \n",
       "4                                             0   \n",
       "\n",
       "   curricular_units_2nd_sem_credited  curricular_units_2nd_sem_enrolled  \\\n",
       "0                                  0                                  0   \n",
       "1                                  0                                  6   \n",
       "2                                  0                                  6   \n",
       "3                                  0                                  6   \n",
       "4                                  0                                  6   \n",
       "\n",
       "   curricular_units_2nd_sem_evaluations  curricular_units_2nd_sem_approved  \\\n",
       "0                                     0                                  0   \n",
       "1                                     6                                  6   \n",
       "2                                     0                                  0   \n",
       "3                                    10                                  5   \n",
       "4                                     6                                  6   \n",
       "\n",
       "   curricular_units_2nd_sem_grade  \\\n",
       "0                          0.0000   \n",
       "1                         13.6667   \n",
       "2                          0.0000   \n",
       "3                         12.4000   \n",
       "4                         13.0000   \n",
       "\n",
       "   curricular_units_2nd_sem_without_evaluations  unemployment_rate  \\\n",
       "0                                             0            10.8000   \n",
       "1                                             0            13.9000   \n",
       "2                                             0            10.8000   \n",
       "3                                             0             9.4000   \n",
       "4                                             0            13.9000   \n",
       "\n",
       "   inflation_rate     gdp  is_single application_mode_risk  is_over_23_entry  \\\n",
       "0          1.4000  1.7400          1           Bajo_Riesgo                 0   \n",
       "1         -0.3000  0.7900          1           Bajo_Riesgo                 0   \n",
       "2          1.4000  1.7400          1           Bajo_Riesgo                 0   \n",
       "3         -0.8000 -3.1200          1           Bajo_Riesgo                 0   \n",
       "4         -0.3000  0.7900          0           Alto_Riesgo                 1   \n",
       "\n",
       "  previous_qualification_risk mothers_qualification_level  \\\n",
       "0                 Bajo_Riesgo                Basica_Media   \n",
       "1                 Bajo_Riesgo                  Secundaria   \n",
       "2                 Bajo_Riesgo                 Basica_Baja   \n",
       "3                 Bajo_Riesgo                Basica_Media   \n",
       "4                 Bajo_Riesgo                 Basica_Baja   \n",
       "\n",
       "  fathers_qualification_level mothers_occupation_level  \\\n",
       "0                  Secundaria             Otro_Trabajo   \n",
       "1                    Superior              Profesional   \n",
       "2                 Basica_Baja             Otro_Trabajo   \n",
       "3                 Basica_Baja             Otro_Trabajo   \n",
       "4                Basica_Media             Otro_Trabajo   \n",
       "\n",
       "  fathers_occupation_level  has_unknown_parent_info  target_binario  \n",
       "0             Otro_Trabajo                        0               1  \n",
       "1              Profesional                        0               0  \n",
       "2             Otro_Trabajo                        0               1  \n",
       "3              Profesional                        0               0  \n",
       "4             Otro_Trabajo                        0               0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar dataset preprocesado\n",
    "df = pd.read_csv('../data/processed/preprocessed_data.csv')\n",
    "\n",
    "print(f\"Dataset cargado: {df.shape[0]} filas x {df.shape[1]} columnas\")\n",
    "print(df['target_binario'].value_counts())\n",
    "print(f\"\\nRatio de desbalance: {df['target_binario'].value_counts()[0] / df['target_binario'].value_counts()[1]:.2f}:1\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-variables",
   "metadata": {},
   "source": [
    "## 2. Definición de variables por fase temporal (T0, T1, T2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "define-variables",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "  VARIABLES POR FASE TEMPORAL\n",
      "================================================================================\n",
      "\n",
      " T0 (Matrícula): 18 variables\n",
      " T1 (Fin 1er Sem): 29 variables (+11)\n",
      " T2 (Fin 2do Sem): 35 variables (+6)\n"
     ]
    }
   ],
   "source": [
    "# TARGET\n",
    "TARGET = 'target_binario'\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# VARIABLES BINARIAS (no requieren encoding, ya son 0/1)\n",
    "# -----------------------------------------------------------------------------\n",
    "VARS_BINARIAS_T0 = [\n",
    "    'daytimeevening_attendance',\n",
    "    'displaced',\n",
    "    'educational_special_needs',\n",
    "    'gender',\n",
    "    'scholarship_holder',\n",
    "    'international',\n",
    "    'is_single'\n",
    "]\n",
    "\n",
    "VARS_BINARIAS_T1 = [\n",
    "    'debtor',\n",
    "    'tuition_fees_up_to_date'\n",
    "]\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# VARIABLES NUMÉRICAS (NO requieren escalado para XGBoost)\n",
    "# -----------------------------------------------------------------------------\n",
    "VARS_NUMERICAS_T0 = [\n",
    "    'age_at_enrollment',\n",
    "    'admission_grade',\n",
    "    'previous_qualification_grade'\n",
    "]\n",
    "\n",
    "VARS_NUMERICAS_T1 = [\n",
    "    'curricular_units_1st_sem_credited',\n",
    "    'curricular_units_1st_sem_enrolled',\n",
    "    'curricular_units_1st_sem_evaluations',\n",
    "    'curricular_units_1st_sem_approved',\n",
    "    'curricular_units_1st_sem_grade',\n",
    "    'curricular_units_1st_sem_without_evaluations',\n",
    "    'unemployment_rate',\n",
    "    'inflation_rate',\n",
    "    'gdp'\n",
    "]\n",
    "\n",
    "VARS_NUMERICAS_T2 = [\n",
    "    'curricular_units_2nd_sem_credited',\n",
    "    'curricular_units_2nd_sem_enrolled',\n",
    "    'curricular_units_2nd_sem_evaluations',\n",
    "    'curricular_units_2nd_sem_approved',\n",
    "    'curricular_units_2nd_sem_grade',\n",
    "    'curricular_units_2nd_sem_without_evaluations'\n",
    "]\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# VARIABLES CATEGÓRICAS AGRUPADAS (requieren Label Encoding para XGBoost)\n",
    "# -----------------------------------------------------------------------------\n",
    "VARS_CATEGORICAS_AGRUPADAS_T0 = [\n",
    "    'application_mode_risk',\n",
    "    'previous_qualification_risk',\n",
    "    'mothers_qualification_level',\n",
    "    'fathers_qualification_level',\n",
    "    'mothers_occupation_level',\n",
    "    'fathers_occupation_level'\n",
    "]\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# VARIABLES CATEGÓRICAS PARA TARGET ENCODING\n",
    "# -----------------------------------------------------------------------------\n",
    "VARS_TARGET_ENCODING_T0 = ['course']\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# VARIABLE ORDINAL (se trata como numérica)\n",
    "# -----------------------------------------------------------------------------\n",
    "VARS_ORDINALES_T0 = ['application_order']\n",
    "\n",
    "# =============================================================================\n",
    "# COMPOSICIÓN DE VARIABLES POR FASE TEMPORAL\n",
    "# =============================================================================\n",
    "\n",
    "# T0: Variables disponibles al momento de matrícula\n",
    "VARS_T0 = (\n",
    "    VARS_BINARIAS_T0 +\n",
    "    VARS_NUMERICAS_T0 +\n",
    "    VARS_CATEGORICAS_AGRUPADAS_T0 +\n",
    "    VARS_TARGET_ENCODING_T0 +\n",
    "    VARS_ORDINALES_T0\n",
    ")\n",
    "\n",
    "# T1: T0 + variables del 1er semestre\n",
    "VARS_T1 = (\n",
    "    VARS_T0 +\n",
    "    VARS_BINARIAS_T1 +\n",
    "    VARS_NUMERICAS_T1\n",
    ")\n",
    "\n",
    "# T2: T1 + variables del 2do semestre\n",
    "VARS_T2 = (\n",
    "    VARS_T1 +\n",
    "    VARS_NUMERICAS_T2\n",
    ")\n",
    "\n",
    "print(\"================================================================================\")\n",
    "print(\"  VARIABLES POR FASE TEMPORAL\")\n",
    "print(\"================================================================================\")\n",
    "print(f\"\\n T0 (Matrícula): {len(VARS_T0)} variables\")\n",
    "print(f\" T1 (Fin 1er Sem): {len(VARS_T1)} variables (+{len(VARS_T1) - len(VARS_T0)})\")\n",
    "print(f\" T2 (Fin 2do Sem): {len(VARS_T2)} variables (+{len(VARS_T2) - len(VARS_T1)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-split",
   "metadata": {},
   "source": [
    "## 3. Split TRAIN/TEST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "train-test-split",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "  SPLIT TRAIN/TEST\n",
      "================================================================================\n",
      "\n",
      "Train: 3539 (80.0%)\n",
      "Test:  885 (20.0%)\n",
      "\n",
      "Distribución del target en Train:\n",
      "target_binario\n",
      "0    2402\n",
      "1    1137\n",
      "Name: count, dtype: int64\n",
      "Ratio de desbalance:: 2.11:1\n",
      "\n",
      "Distribución del target en Test:\n",
      "target_binario\n",
      "0    601\n",
      "1    284\n",
      "Name: count, dtype: int64\n",
      "Ratio de desbalance:: 2.12:1\n"
     ]
    }
   ],
   "source": [
    "# Split se hace en totalidad del dataste, posteriormente se seleccionan las variables según la fase temporal para entrenemiento y evaluaciónl\n",
    "\n",
    "X = df[VARS_T2].copy()\n",
    "y = df[TARGET].copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(\"================================================================================\")\n",
    "print(\"  SPLIT TRAIN/TEST\")\n",
    "print(\"================================================================================\")\n",
    "print(f\"\\nTrain: {X_train.shape[0]} ({X_train.shape[0]/len(df)*100:.1f}%)\")\n",
    "print(f\"Test:  {X_test.shape[0]} ({X_test.shape[0]/len(df)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nDistribución del target en Train:\")\n",
    "print(y_train.value_counts())\n",
    "print(f\"Ratio de desbalance:: {y_train.value_counts()[0] / y_train.value_counts()[1]:.2f}:1\")\n",
    "\n",
    "print(f\"\\nDistribución del target en Test:\")\n",
    "print(y_test.value_counts())\n",
    "print(f\"Ratio de desbalance:: {y_test.value_counts()[0] / y_test.value_counts()[1]:.2f}:1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-preprocessing",
   "metadata": {},
   "source": [
    "## 4. Funciones de preprocesamiento para XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "preprocessing-functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtiene_variables_por_fase(fase):\n",
    "    # Retorna las listas de variables según la fase temporal, retorna diccionario con variables de la fase\n",
    "    if fase == 'T0':\n",
    "        return {\n",
    "            'binarias': VARS_BINARIAS_T0,\n",
    "            'numericas': VARS_NUMERICAS_T0 + VARS_ORDINALES_T0,\n",
    "            'categoricas_le': VARS_CATEGORICAS_AGRUPADAS_T0,\n",
    "            'categoricas_te': VARS_TARGET_ENCODING_T0,\n",
    "            'all': VARS_T0\n",
    "        }\n",
    "    elif fase == 'T1':\n",
    "        return {\n",
    "            'binarias': VARS_BINARIAS_T0 + VARS_BINARIAS_T1,\n",
    "            'numericas': VARS_NUMERICAS_T0 + VARS_ORDINALES_T0 + VARS_NUMERICAS_T1,\n",
    "            'categoricas_le': VARS_CATEGORICAS_AGRUPADAS_T0,\n",
    "            'categoricas_te': VARS_TARGET_ENCODING_T0,\n",
    "            'all': VARS_T1\n",
    "        }\n",
    "    elif fase == 'T2':\n",
    "        return {\n",
    "            'binarias': VARS_BINARIAS_T0 + VARS_BINARIAS_T1,\n",
    "            'numericas': VARS_NUMERICAS_T0 + VARS_ORDINALES_T0 + VARS_NUMERICAS_T1 + VARS_NUMERICAS_T2,\n",
    "            'categoricas_le': VARS_CATEGORICAS_AGRUPADAS_T0,\n",
    "            'categoricas_te': VARS_TARGET_ENCODING_T0,\n",
    "            'all': VARS_T2\n",
    "        }\n",
    "    else:\n",
    "        raise ValueError(f\"Fase no válida: {fase}. Usar 'T0', 'T1', o 'T2'\")\n",
    "\n",
    "\n",
    "def preprocesamiento_xgboost(X_train, X_test, y_train, fase):\n",
    "    # Preprocesa los datos para XGBoost    \n",
    "    variables_fase = obtiene_variables_por_fase(fase)\n",
    "    \n",
    "    # Seleccionar solo las variables de la fase\n",
    "    X_train_fase = X_train[variables_fase['all']].copy()\n",
    "    X_test_fase = X_test[variables_fase['all']].copy()\n",
    "    \n",
    "    # Diccionario para guardar encoders\n",
    "    label_encoders = {}\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # 1. TARGET ENCODING para 'course' \n",
    "    # -------------------------------------------------------------------------\n",
    "    te = TargetEncoder(cols=variables_fase['categoricas_te'], smoothing=0.3)\n",
    "    \n",
    "    for col in variables_fase['categoricas_te']:\n",
    "        X_train_fase[col + '_encoded'] = te.fit_transform(X_train_fase[[col]], y_train)[col]\n",
    "        X_test_fase[col + '_encoded'] = te.transform(X_test_fase[[col]])[col]\n",
    "        # Eliminar columna original\n",
    "        X_train_fase = X_train_fase.drop(columns=[col])\n",
    "        X_test_fase = X_test_fase.drop(columns=[col])\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # 2. LABEL ENCODING para categóricas agrupadas\n",
    "    # -------------------------------------------------------------------------\n",
    "    for col in variables_fase['categoricas_le']:\n",
    "        le = LabelEncoder()\n",
    "        X_train_fase[col] = le.fit_transform(X_train_fase[col].astype(str))\n",
    "        X_test_fase[col] = le.transform(X_test_fase[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # Guardar información\n",
    "    # -------------------------------------------------------------------------\n",
    "    variables = X_train_fase.columns.tolist()\n",
    "    preprocessors = {\n",
    "        'target_encoder': te,\n",
    "        'label_encoders': label_encoders,\n",
    "        'feature_names': variables\n",
    "    }\n",
    "    \n",
    "    return X_train_fase, X_test_fase, variables, preprocessors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-cv-functions",
   "metadata": {},
   "source": [
    "## 5. Funciones entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "training-functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrena_xgboost(X_train, y_train, fase, cv_folds=5):\n",
    "    \"\"\"Entrena y evalúa XGBoost con Cross-Validation.\"\"\"\n",
    "\n",
    "    mlflow.end_run()\n",
    "         \n",
    "    print(\"================================================================================\")\n",
    "    print(f\"  ENTRENAMIENTO XGBOOST - FASE {fase}\")\n",
    "    print(\"================================================================================\")\n",
    "    print(f\"\\nVariables: {X_train.shape[1]}\")\n",
    "    print(f\"Registros: {X_train.shape[0]}\")\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # Calcular scale_pos_weight para desbalance\n",
    "    # -------------------------------------------------------------------------\n",
    "    n_neg = (y_train == 0).sum()\n",
    "    n_pos = (y_train == 1).sum()\n",
    "    scale_pos_weight = n_neg / n_pos\n",
    "    print(f\"\\nscale_pos_weight: {scale_pos_weight:.2f}\")\n",
    "\n",
    "    print(f\"\\nHiperparámetros (por defecto):\")\n",
    "    print(f\"   • n_estimators: 100\")\n",
    "    print(f\"   • max_depth: 6\")\n",
    "    print(f\"   • learning_rate: 0.3\")\n",
    "    print(f\"   • subsample: 1.0\")\n",
    "    print(f\"   • colsample_bytree: 1.0\")\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # Cross-Validation con loop manual\n",
    "    # -------------------------------------------------------------------------\n",
    "    print(f\"\\nCross-Validation ({cv_folds}-fold):\")\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=RANDOM_STATE)\n",
    "    \n",
    "    # Almacenar resultados por fold\n",
    "    cv_results = {\n",
    "        'train_accuracy': [], 'test_accuracy': [],\n",
    "        'train_precision': [], 'test_precision': [],\n",
    "        'train_recall': [], 'test_recall': [],\n",
    "        'train_f1': [], 'test_f1': [],\n",
    "        'train_roc_auc': [], 'test_roc_auc': []\n",
    "    }\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(cv.split(X_train, y_train)):\n",
    "        X_fold_train = X_train.iloc[train_idx]\n",
    "        X_fold_val = X_train.iloc[val_idx]\n",
    "        y_fold_train = y_train.iloc[train_idx]\n",
    "        y_fold_val = y_train.iloc[val_idx]\n",
    "        \n",
    "        # Crear y entrenar modelo\n",
    "        model = XGBClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=6,\n",
    "            learning_rate=0.3,\n",
    "            subsample=1.0,\n",
    "            colsample_bytree=1.0,\n",
    "            min_child_weight=1,\n",
    "            gamma=0,\n",
    "            reg_alpha=0,\n",
    "            reg_lambda=1,\n",
    "            scale_pos_weight=scale_pos_weight,\n",
    "            objective='binary:logistic',\n",
    "            eval_metric='logloss',\n",
    "            use_label_encoder=False,\n",
    "            random_state=RANDOM_STATE,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        model.fit(X_fold_train, y_fold_train)\n",
    "        \n",
    "        # Predicciones\n",
    "        y_train_pred = model.predict(X_fold_train)\n",
    "        y_train_proba = model.predict_proba(X_fold_train)[:, 1]\n",
    "        y_val_pred = model.predict(X_fold_val)\n",
    "        y_val_proba = model.predict_proba(X_fold_val)[:, 1]\n",
    "        \n",
    "        # Métricas Train\n",
    "        cv_results['train_accuracy'].append(accuracy_score(y_fold_train, y_train_pred))\n",
    "        cv_results['train_precision'].append(precision_score(y_fold_train, y_train_pred))\n",
    "        cv_results['train_recall'].append(recall_score(y_fold_train, y_train_pred))\n",
    "        cv_results['train_f1'].append(f1_score(y_fold_train, y_train_pred))\n",
    "        cv_results['train_roc_auc'].append(roc_auc_score(y_fold_train, y_train_proba))\n",
    "        \n",
    "        # Métricas Validation\n",
    "        cv_results['test_accuracy'].append(accuracy_score(y_fold_val, y_val_pred))\n",
    "        cv_results['test_precision'].append(precision_score(y_fold_val, y_val_pred))\n",
    "        cv_results['test_recall'].append(recall_score(y_fold_val, y_val_pred))\n",
    "        cv_results['test_f1'].append(f1_score(y_fold_val, y_val_pred))\n",
    "        cv_results['test_roc_auc'].append(roc_auc_score(y_fold_val, y_val_proba))\n",
    "    \n",
    "    # Convertir a numpy arrays\n",
    "    for key in cv_results:\n",
    "        cv_results[key] = np.array(cv_results[key])\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # Resultados por fold\n",
    "    # -------------------------------------------------------------------------\n",
    "    print(\"\\n Resultados por fold:\")\n",
    "    for i in range(cv_folds):\n",
    "        print(f\"\\n  Fold {i+1}:\")\n",
    "        for metric in ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']:\n",
    "            train_score = cv_results[f'train_{metric}'][i]\n",
    "            val_score = cv_results[f'test_{metric}'][i]\n",
    "            print(f\"    {metric:<10} | Train: {train_score:.4f} | Val: {val_score:.4f}\")\n",
    "\n",
    "\n",
    "    mlflow.set_experiment(\"TFM_Dropout_Prediction\")\n",
    "    with mlflow.start_run(run_name=f\"XGBoost_CV5_{fase}\"):\n",
    "        mlflow.set_tag(\"modelo\", 'Params por default')\n",
    "        mlflow.set_tag(\"tipo\", 'Validacion cruzada')\n",
    "        mlflow.log_params(model.get_params())\n",
    "\n",
    "        # -------------------------------------------------------------------------\n",
    "        # Resumen CV (media ± std)\n",
    "        # -------------------------------------------------------------------------\n",
    "        print(f\"\\n Resumen Cross-Validation:\")\n",
    "        print(f\"\\n   {'Métrica':<12} {'Train Mean':>12} {'Train Std':>12} {'Val Mean':>12} {'Val Std':>12}\")\n",
    "        print(f\"   {'-'*60}\")\n",
    "        for metric in ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']:\n",
    "            train_mean = cv_results[f'train_{metric}'].mean()\n",
    "            train_std = cv_results[f'train_{metric}'].std()\n",
    "            val_mean = cv_results[f'test_{metric}'].mean()\n",
    "            val_std = cv_results[f'test_{metric}'].std()\n",
    "            # mlflow\n",
    "            mlflow.log_metric(f'test_{metric}_mean', val_mean.round(4))\n",
    "            mlflow.log_metric(f'test_{metric}_std', val_std.round(4))\n",
    "            print(f\"   {metric:<12} {train_mean:>12.4f} {train_std:>12.4f} {val_mean:>12.4f} {val_std:>12.4f}\")\n",
    "    \n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # Retornar resultados\n",
    "    # -------------------------------------------------------------------------\n",
    "    results = {\n",
    "        'phase': fase,\n",
    "        'model': model,\n",
    "        'n_features': X_train.shape[1],\n",
    "        'cv_results': cv_results,\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "def resumen_cv(cv_results, fase, modelo):\n",
    "    metrics = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "\n",
    "    summary = {\n",
    "        'modelo': modelo,\n",
    "        'fase': fase\n",
    "    }\n",
    "\n",
    "\n",
    "    # -------------------------\n",
    "    # Métricas de VALIDACIÓN\n",
    "    # -------------------------\n",
    "    for metric in metrics:\n",
    "        summary[f'{metric}_val_mean'] = cv_results[f'test_{metric}'].mean()\n",
    "        summary[f'{metric}_val_std']  = cv_results[f'test_{metric}'].std()\n",
    "        \n",
    "\n",
    "    # -------------------------\n",
    "    # Métricas de TRAIN\n",
    "    # -------------------------\n",
    "    for metric in metrics:\n",
    "        summary[f'{metric}_train_mean'] = cv_results[f'train_{metric}'].mean()\n",
    "        summary[f'{metric}_train_std']  = cv_results[f'train_{metric}'].std()\n",
    "\n",
    "\n",
    "    return pd.DataFrame([summary])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-t0",
   "metadata": {},
   "source": [
    "## 6. Modelado FASE T0 (MATRÍCULA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "model-t0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "T0 - Dimensiones después del preprocesamiento:\n",
      "   Train: (3539, 18)\n",
      "   Test:  (885, 18)\n",
      "   Variables: 18\n",
      "   \n",
      "Las variables son:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['daytimeevening_attendance', 'displaced', 'educational_special_needs',\n",
       "       'gender', 'scholarship_holder', 'international', 'is_single',\n",
       "       'age_at_enrollment', 'admission_grade', 'previous_qualification_grade',\n",
       "       'application_mode_risk', 'previous_qualification_risk',\n",
       "       'mothers_qualification_level', 'fathers_qualification_level',\n",
       "       'mothers_occupation_level', 'fathers_occupation_level',\n",
       "       'application_order', 'course_encoded'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocesamiento para T0\n",
    "X_train_T0, X_test_T0, features_T0, prep_T0 = preprocesamiento_xgboost(\n",
    "    X_train, X_test, y_train, fase='T0'\n",
    ")\n",
    "\n",
    "print(f\"\\nT0 - Dimensiones después del preprocesamiento:\")\n",
    "print(f\"   Train: {X_train_T0.shape}\")\n",
    "print(f\"   Test:  {X_test_T0.shape}\")\n",
    "print(f\"   Variables: {len(features_T0)}\")\n",
    "print(f\"   \\nLas variables son:\")\n",
    "X_train_T0.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "train-t0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "  ENTRENAMIENTO XGBOOST - FASE T0\n",
      "================================================================================\n",
      "\n",
      "Variables: 18\n",
      "Registros: 3539\n",
      "\n",
      "scale_pos_weight: 2.11\n",
      "\n",
      "Hiperparámetros (por defecto):\n",
      "   • n_estimators: 100\n",
      "   • max_depth: 6\n",
      "   • learning_rate: 0.3\n",
      "   • subsample: 1.0\n",
      "   • colsample_bytree: 1.0\n",
      "\n",
      "Cross-Validation (5-fold):\n",
      "\n",
      " Resultados por fold:\n",
      "\n",
      "  Fold 1:\n",
      "    accuracy   | Train: 0.9700 | Val: 0.7020\n",
      "    precision  | Train: 0.9383 | Val: 0.5399\n",
      "    recall     | Train: 0.9703 | Val: 0.5044\n",
      "    f1         | Train: 0.9540 | Val: 0.5215\n",
      "    roc_auc    | Train: 0.9967 | Val: 0.7090\n",
      "\n",
      "  Fold 2:\n",
      "    accuracy   | Train: 0.9820 | Val: 0.7020\n",
      "    precision  | Train: 0.9574 | Val: 0.5374\n",
      "    recall     | Train: 0.9879 | Val: 0.5351\n",
      "    f1         | Train: 0.9724 | Val: 0.5363\n",
      "    roc_auc    | Train: 0.9990 | Val: 0.7137\n",
      "\n",
      "  Fold 3:\n",
      "    accuracy   | Train: 0.9749 | Val: 0.6907\n",
      "    precision  | Train: 0.9439 | Val: 0.5161\n",
      "    recall     | Train: 0.9802 | Val: 0.5639\n",
      "    f1         | Train: 0.9617 | Val: 0.5389\n",
      "    roc_auc    | Train: 0.9980 | Val: 0.7110\n",
      "\n",
      "  Fold 4:\n",
      "    accuracy   | Train: 0.9717 | Val: 0.6921\n",
      "    precision  | Train: 0.9368 | Val: 0.5188\n",
      "    recall     | Train: 0.9780 | Val: 0.5463\n",
      "    f1         | Train: 0.9570 | Val: 0.5322\n",
      "    roc_auc    | Train: 0.9971 | Val: 0.7294\n",
      "\n",
      "  Fold 5:\n",
      "    accuracy   | Train: 0.9739 | Val: 0.6549\n",
      "    precision  | Train: 0.9409 | Val: 0.4664\n",
      "    recall     | Train: 0.9802 | Val: 0.5198\n",
      "    f1         | Train: 0.9602 | Val: 0.4917\n",
      "    roc_auc    | Train: 0.9971 | Val: 0.7019\n",
      "\n",
      " Resumen Cross-Validation:\n",
      "\n",
      "   Métrica        Train Mean    Train Std     Val Mean      Val Std\n",
      "   ------------------------------------------------------------\n",
      "   accuracy           0.9745       0.0041       0.6883       0.0174\n",
      "   precision          0.9435       0.0074       0.5157       0.0265\n",
      "   recall             0.9793       0.0056       0.5339       0.0206\n",
      "   f1                 0.9611       0.0063       0.5241       0.0173\n",
      "   roc_auc            0.9976       0.0008       0.7130       0.0091\n",
      "🏃 View run XGBoost_CV5_T0 at: http://127.0.0.1:5000/#/experiments/570026133514462797/runs/a6b00060c53c4e6d85189094c408c341\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/570026133514462797\n",
      "Resultados guardados en: ../outputs/models/XGBoost/cv_summary_XGBoost.csv\n"
     ]
    }
   ],
   "source": [
    "# Entrenar y evaluar T0\n",
    "results_T0 = entrena_xgboost(X_train_T0, y_train, fase='T0')\n",
    "\n",
    "df_resumen_xgboost = resumen_cv(\n",
    "    cv_results=results_T0['cv_results'],\n",
    "    fase='T0',\n",
    "    modelo='XGBoost'\n",
    ")\n",
    "# Guardar tabla de comparación\n",
    "df_resumen_xgboost.to_csv(f\"{OUTPUT_DIR_REPORTES}cv_summary_XGBoost.csv\", index=False)\n",
    "\n",
    "print(f\"Resultados guardados en: {OUTPUT_DIR_REPORTES}cv_summary_XGBoost.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34984a5",
   "metadata": {},
   "source": [
    "### Comentarios FASE 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa00e7f3",
   "metadata": {},
   "source": [
    "1. Se observa que todas las métricas en entrenamiento alcanzan casi el valor máximo (1.0) lo que indica sobreentrenamiento fuerte, aunque ligeramente menor en comparación con RF en Fase 0. El recall en validación es 0.5445, inferior RL.\n",
    "2. Las métricas de validación caen de forma relevente, en proemdio 0.2276, en consecuencia, no generaliza adecuadamente y desviación standard presentan mayor variación (promedio 0.0201)\n",
    "3. XGBoost no aporta ventaja en fase T0 y presenta sobreajuste."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-t1",
   "metadata": {},
   "source": [
    "## 7. Modelado FASE T1 (FIN 1ER SEMESTRE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "model-t1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "T1 - Dimensiones después del preprocesamiento:\n",
      "   Train: (3539, 29)\n",
      "   Test:  (885, 29)\n",
      "   Features: 29\n",
      "   \n",
      "Las variables son:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['daytimeevening_attendance', 'displaced', 'educational_special_needs',\n",
       "       'gender', 'scholarship_holder', 'international', 'is_single',\n",
       "       'age_at_enrollment', 'admission_grade', 'previous_qualification_grade',\n",
       "       'application_mode_risk', 'previous_qualification_risk',\n",
       "       'mothers_qualification_level', 'fathers_qualification_level',\n",
       "       'mothers_occupation_level', 'fathers_occupation_level',\n",
       "       'application_order', 'debtor', 'tuition_fees_up_to_date',\n",
       "       'curricular_units_1st_sem_credited',\n",
       "       'curricular_units_1st_sem_enrolled',\n",
       "       'curricular_units_1st_sem_evaluations',\n",
       "       'curricular_units_1st_sem_approved', 'curricular_units_1st_sem_grade',\n",
       "       'curricular_units_1st_sem_without_evaluations', 'unemployment_rate',\n",
       "       'inflation_rate', 'gdp', 'course_encoded'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocesamiento para T1\n",
    "X_train_T1, X_test_T1, features_T1, prep_T1 = preprocesamiento_xgboost(\n",
    "    X_train, X_test, y_train, fase='T1'\n",
    ")\n",
    "\n",
    "print(f\"\\nT1 - Dimensiones después del preprocesamiento:\")\n",
    "print(f\"   Train: {X_train_T1.shape}\")\n",
    "print(f\"   Test:  {X_test_T1.shape}\")\n",
    "print(f\"   Features: {len(features_T1)}\")\n",
    "print(f\"   \\nLas variables son:\")\n",
    "X_train_T1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "train-t1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "  ENTRENAMIENTO XGBOOST - FASE T1\n",
      "================================================================================\n",
      "\n",
      "Variables: 29\n",
      "Registros: 3539\n",
      "\n",
      "scale_pos_weight: 2.11\n",
      "\n",
      "Hiperparámetros (por defecto):\n",
      "   • n_estimators: 100\n",
      "   • max_depth: 6\n",
      "   • learning_rate: 0.3\n",
      "   • subsample: 1.0\n",
      "   • colsample_bytree: 1.0\n",
      "\n",
      "Cross-Validation (5-fold):\n",
      "\n",
      " Resultados por fold:\n",
      "\n",
      "  Fold 1:\n",
      "    accuracy   | Train: 1.0000 | Val: 0.8404\n",
      "    precision  | Train: 1.0000 | Val: 0.7602\n",
      "    recall     | Train: 1.0000 | Val: 0.7368\n",
      "    f1         | Train: 1.0000 | Val: 0.7483\n",
      "    roc_auc    | Train: 1.0000 | Val: 0.8785\n",
      "\n",
      "  Fold 2:\n",
      "    accuracy   | Train: 0.9996 | Val: 0.8333\n",
      "    precision  | Train: 0.9989 | Val: 0.7644\n",
      "    recall     | Train: 1.0000 | Val: 0.6974\n",
      "    f1         | Train: 0.9995 | Val: 0.7294\n",
      "    roc_auc    | Train: 1.0000 | Val: 0.8783\n",
      "\n",
      "  Fold 3:\n",
      "    accuracy   | Train: 0.9996 | Val: 0.8164\n",
      "    precision  | Train: 0.9989 | Val: 0.7175\n",
      "    recall     | Train: 1.0000 | Val: 0.7048\n",
      "    f1         | Train: 0.9995 | Val: 0.7111\n",
      "    roc_auc    | Train: 1.0000 | Val: 0.8879\n",
      "\n",
      "  Fold 4:\n",
      "    accuracy   | Train: 0.9996 | Val: 0.8376\n",
      "    precision  | Train: 0.9989 | Val: 0.7617\n",
      "    recall     | Train: 1.0000 | Val: 0.7181\n",
      "    f1         | Train: 0.9995 | Val: 0.7392\n",
      "    roc_auc    | Train: 1.0000 | Val: 0.8835\n",
      "\n",
      "  Fold 5:\n",
      "    accuracy   | Train: 0.9996 | Val: 0.8515\n",
      "    precision  | Train: 0.9989 | Val: 0.7824\n",
      "    recall     | Train: 1.0000 | Val: 0.7445\n",
      "    f1         | Train: 0.9995 | Val: 0.7630\n",
      "    roc_auc    | Train: 1.0000 | Val: 0.8961\n",
      "\n",
      " Resumen Cross-Validation:\n",
      "\n",
      "   Métrica        Train Mean    Train Std     Val Mean      Val Std\n",
      "   ------------------------------------------------------------\n",
      "   accuracy           0.9997       0.0001       0.8358       0.0114\n",
      "   precision          0.9991       0.0004       0.7572       0.0214\n",
      "   recall             1.0000       0.0000       0.7203       0.0180\n",
      "   f1                 0.9996       0.0002       0.7382       0.0175\n",
      "   roc_auc            1.0000       0.0000       0.8849       0.0066\n",
      "🏃 View run XGBoost_CV5_T1 at: http://127.0.0.1:5000/#/experiments/570026133514462797/runs/946bb14dfd414db2bdcb9287ed3182d1\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/570026133514462797\n",
      "\n",
      "Resultados guardados en: ../outputs/models/XGBoost/cv_summary_XGBoost.csv\n"
     ]
    }
   ],
   "source": [
    "# Entrenar y evaluar T1\n",
    "results_T1 = entrena_xgboost(X_train_T1, y_train, fase='T1')\n",
    "\n",
    "df_resumen_XGBoost_T1 = resumen_cv(\n",
    "    cv_results=results_T1['cv_results'],\n",
    "    fase='T1',\n",
    "    modelo='XGBoost'\n",
    ")\n",
    "\n",
    "xg_path = \"../outputs/models/XGBoost/cv_summary_XGBoost.csv\"\n",
    "df_xg = pd.read_csv(xg_path)\n",
    "df_final = pd.concat([df_xg, df_resumen_XGBoost_T1], ignore_index=True)\n",
    "\n",
    "# Guardar tabla de comparación\n",
    "df_final.to_csv(xg_path, index=False)\n",
    "print(f\"\\nResultados guardados en: {OUTPUT_DIR_REPORTES}cv_summary_XGBoost.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4da3a7",
   "metadata": {},
   "source": [
    "### Comentarios FASE 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fb6b83",
   "metadata": {},
   "source": [
    "1. Se observa que casi la totalidad de las métricas en entrenamiento alcanzan el valor máximo (1.0) lo que indica sobreentrenamiento severo. El recall en validación es 0.7071, similar a RL y RF.\n",
    "2. Las métricas de validación caen de forma relevente, en promedio 0.12, en consecuencia, no generaliza adecuadamente. Desviación standard presentan menor variación (promedio 0.0138) que la Fase 0 presentando una estabilidad relativa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-t2",
   "metadata": {},
   "source": [
    "## 8. Modelado FASE T2 (FIN 2DO SEMESTRE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "model-t2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "T2 - Dimensiones después del preprocesamiento:\n",
      "   Train: (3539, 35)\n",
      "   Test:  (885, 35)\n",
      "   Features: 35\n",
      "   \n",
      "Las variables son:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['daytimeevening_attendance', 'displaced', 'educational_special_needs',\n",
       "       'gender', 'scholarship_holder', 'international', 'is_single',\n",
       "       'age_at_enrollment', 'admission_grade', 'previous_qualification_grade',\n",
       "       'application_mode_risk', 'previous_qualification_risk',\n",
       "       'mothers_qualification_level', 'fathers_qualification_level',\n",
       "       'mothers_occupation_level', 'fathers_occupation_level',\n",
       "       'application_order', 'debtor', 'tuition_fees_up_to_date',\n",
       "       'curricular_units_1st_sem_credited',\n",
       "       'curricular_units_1st_sem_enrolled',\n",
       "       'curricular_units_1st_sem_evaluations',\n",
       "       'curricular_units_1st_sem_approved', 'curricular_units_1st_sem_grade',\n",
       "       'curricular_units_1st_sem_without_evaluations', 'unemployment_rate',\n",
       "       'inflation_rate', 'gdp', 'curricular_units_2nd_sem_credited',\n",
       "       'curricular_units_2nd_sem_enrolled',\n",
       "       'curricular_units_2nd_sem_evaluations',\n",
       "       'curricular_units_2nd_sem_approved', 'curricular_units_2nd_sem_grade',\n",
       "       'curricular_units_2nd_sem_without_evaluations', 'course_encoded'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocesamiento para T2\n",
    "X_train_T2, X_test_T2, features_T2, prep_T2 = preprocesamiento_xgboost(\n",
    "    X_train, X_test, y_train, fase='T2'\n",
    ")\n",
    "\n",
    "print(f\"\\nT2 - Dimensiones después del preprocesamiento:\")\n",
    "print(f\"   Train: {X_train_T2.shape}\")\n",
    "print(f\"   Test:  {X_test_T2.shape}\")\n",
    "print(f\"   Features: {len(features_T2)}\")\n",
    "print(f\"   \\nLas variables son:\")\n",
    "X_train_T2.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "train-t2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "  ENTRENAMIENTO XGBOOST - FASE T2\n",
      "================================================================================\n",
      "\n",
      "Variables: 35\n",
      "Registros: 3539\n",
      "\n",
      "scale_pos_weight: 2.11\n",
      "\n",
      "Hiperparámetros (por defecto):\n",
      "   • n_estimators: 100\n",
      "   • max_depth: 6\n",
      "   • learning_rate: 0.3\n",
      "   • subsample: 1.0\n",
      "   • colsample_bytree: 1.0\n",
      "\n",
      "Cross-Validation (5-fold):\n",
      "\n",
      " Resultados por fold:\n",
      "\n",
      "  Fold 1:\n",
      "    accuracy   | Train: 0.9996 | Val: 0.8573\n",
      "    precision  | Train: 0.9989 | Val: 0.7822\n",
      "    recall     | Train: 1.0000 | Val: 0.7719\n",
      "    f1         | Train: 0.9995 | Val: 0.7770\n",
      "    roc_auc    | Train: 1.0000 | Val: 0.8944\n",
      "\n",
      "  Fold 2:\n",
      "    accuracy   | Train: 1.0000 | Val: 0.8503\n",
      "    precision  | Train: 1.0000 | Val: 0.7824\n",
      "    recall     | Train: 1.0000 | Val: 0.7412\n",
      "    f1         | Train: 1.0000 | Val: 0.7613\n",
      "    roc_auc    | Train: 1.0000 | Val: 0.9039\n",
      "\n",
      "  Fold 3:\n",
      "    accuracy   | Train: 1.0000 | Val: 0.8559\n",
      "    precision  | Train: 1.0000 | Val: 0.7934\n",
      "    recall     | Train: 1.0000 | Val: 0.7445\n",
      "    f1         | Train: 1.0000 | Val: 0.7682\n",
      "    roc_auc    | Train: 1.0000 | Val: 0.9043\n",
      "\n",
      "  Fold 4:\n",
      "    accuracy   | Train: 1.0000 | Val: 0.8602\n",
      "    precision  | Train: 1.0000 | Val: 0.8107\n",
      "    recall     | Train: 1.0000 | Val: 0.7357\n",
      "    f1         | Train: 1.0000 | Val: 0.7714\n",
      "    roc_auc    | Train: 1.0000 | Val: 0.9021\n",
      "\n",
      "  Fold 5:\n",
      "    accuracy   | Train: 1.0000 | Val: 0.8699\n",
      "    precision  | Train: 1.0000 | Val: 0.8140\n",
      "    recall     | Train: 1.0000 | Val: 0.7709\n",
      "    f1         | Train: 1.0000 | Val: 0.7919\n",
      "    roc_auc    | Train: 1.0000 | Val: 0.9184\n",
      "\n",
      " Resumen Cross-Validation:\n",
      "\n",
      "   Métrica        Train Mean    Train Std     Val Mean      Val Std\n",
      "   ------------------------------------------------------------\n",
      "   accuracy           0.9999       0.0001       0.8587       0.0064\n",
      "   precision          0.9998       0.0004       0.7965       0.0135\n",
      "   recall             1.0000       0.0000       0.7529       0.0154\n",
      "   f1                 0.9999       0.0002       0.7739       0.0103\n",
      "   roc_auc            1.0000       0.0000       0.9046       0.0078\n",
      "🏃 View run XGBoost_CV5_T2 at: http://127.0.0.1:5000/#/experiments/570026133514462797/runs/b18a006f48954980a5d450a479913737\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/570026133514462797\n",
      "\n",
      "Resultados guardados en: ../outputs/models/XGBoost/cv_summary_XGBoost.csv\n"
     ]
    }
   ],
   "source": [
    "# Entrenar y evaluar T2\n",
    "results_T2 = entrena_xgboost(X_train_T2, y_train, fase='T2')\n",
    "\n",
    "df_resumen_XGBoost_T2 = resumen_cv(\n",
    "    cv_results=results_T2['cv_results'],\n",
    "    fase='T2',\n",
    "    modelo='XGBoost'\n",
    ")\n",
    "\n",
    "xg_path = \"../outputs/models/XGBoost/cv_summary_XGBoost.csv\"\n",
    "df_xg = pd.read_csv(xg_path)\n",
    "df_final = pd.concat([df_xg, df_resumen_XGBoost_T2], ignore_index=True)\n",
    "\n",
    "# Guardar tabla de comparación\n",
    "df_final.to_csv(xg_path, index=False)\n",
    "print(f\"\\nResultados guardados en: {OUTPUT_DIR_REPORTES}cv_summary_XGBoost.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3e2930",
   "metadata": {},
   "source": [
    "### Comentarios FASE 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db75faa7",
   "metadata": {},
   "source": [
    "1. Continua presentando las métricas en entrenamiento con valor máximo (1.0) lo que indica sobreentrenamiento severo. El recall en validación es 0.7485 y un AUC 0.9080, reflejando mayor capacidad predictiva.\n",
    "2. Las métricas de validación caen de forma relevente, en promedio 0.2544, en consecuencia, no generaliza adecuadamente.  Desviación standard presentan mayor variación (promedio 0.0162) mejor que la fase 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba5f5a1",
   "metadata": {},
   "source": [
    "## 9. Resumen Final XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "758bf057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "  RESUMEN XGBoost - CROSS VALIDATION\n",
      "================================================================================\n",
      " modelo fase  accuracy_val_mean  accuracy_val_std  precision_val_mean  precision_val_std  recall_val_mean  recall_val_std  f1_val_mean  f1_val_std  roc_auc_val_mean  roc_auc_val_std  accuracy_train_mean  accuracy_train_std  precision_train_mean  precision_train_std  recall_train_mean  recall_train_std  f1_train_mean  f1_train_std  roc_auc_train_mean  roc_auc_train_std\n",
      "XGBoost   T0             0.6883            0.0174              0.5157             0.0265           0.5339          0.0206       0.5241      0.0173            0.7130           0.0091               0.9745              0.0041                0.9435               0.0074             0.9793            0.0056         0.9611        0.0063              0.9976             0.0008\n",
      "XGBoost   T1             0.8358            0.0114              0.7572             0.0214           0.7203          0.0180       0.7382      0.0175            0.8849           0.0066               0.9997              0.0001                0.9991               0.0004             1.0000            0.0000         0.9996        0.0002              1.0000             0.0000\n",
      "XGBoost   T2             0.8587            0.0064              0.7965             0.0135           0.7529          0.0154       0.7739      0.0103            0.9046           0.0078               0.9999              0.0001                0.9998               0.0004             1.0000            0.0000         0.9999        0.0002              1.0000             0.0000\n"
     ]
    }
   ],
   "source": [
    "# Mostrar resumen final\n",
    "df_final = pd.read_csv(f\"{OUTPUT_DIR_REPORTES}cv_summary_XGBoost.csv\")\n",
    "\n",
    "print(\"================================================================================\")\n",
    "print(\"  RESUMEN XGBoost - CROSS VALIDATION\")\n",
    "print(\"================================================================================\")\n",
    "print(df_final.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb48f15",
   "metadata": {},
   "source": [
    "## 10. Resumen completo de entrenamiento (Todos los algoritmos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a3bcf9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados guardados en: ../outputs/models/cv_summary_entrenamiento.csv\n"
     ]
    }
   ],
   "source": [
    "resumen_path = \"../outputs/models/cv_summary_entrenamiento.csv\"\n",
    "df_resumen = pd.read_csv(resumen_path)\n",
    "\n",
    "xg_path = \"../outputs/models/XGBoost/cv_summary_XGBoost.csv\"\n",
    "df_xg = pd.read_csv(xg_path)\n",
    "\n",
    "df_resumen = pd.concat([df_resumen, df_xg], ignore_index=True)\n",
    "\n",
    "# Guardar tabla de comparación\n",
    "df_resumen.to_csv(f\"../outputs/models/cv_summary_entrenamiento.csv\", index=False)\n",
    "\n",
    "print(f\"Resultados guardados en: ../outputs/models/cv_summary_entrenamiento.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aeb4343",
   "metadata": {},
   "source": [
    "## Conclusión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621dbaa8",
   "metadata": {},
   "source": [
    "Aunque XGBoost presenta desviaciones standard moderadas mas altas que RL y similares a RF, estan se disminuyen en la medida que se agrega más información. En comparación con RF presenta mejor recall, AUC y menor varianza, sin emabargo, al comparar con RL, este algoritmo presenta menor capacidad de detectar a los estudiantes desertores y menor capacidad de discriminación. Si bien presenta una mejora relevante al incoporar información académica en las fases 1 y 2, presenta un sobreaprendizaje en el conjunto de entrenamiento, lo cual sugiere la necesidad de una optmización adecuada de los los hiperparámetros."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFM_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
