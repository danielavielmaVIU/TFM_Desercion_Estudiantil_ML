{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# MODELADO XGBOOST (SIN OPTIMIZACIÓN)\n",
    "\n",
    "Objetivo: Entrenar modelo XGBoost con hiperparámetros por defecto para comparar con el baseline (Regresión Logística).\n",
    "\n",
    "Fases temporales:\n",
    "- T0 (Matrícula)          : Variables disponibles al momento de inscripción\n",
    "- T1 (Fin 1er Semestre)   : T0 + variables académicas del 1er semestre\n",
    "- T2 (Fin 2do Semestre)   : T1 + variables académicas del 2do semestre\n",
    "\n",
    "Preprocesamiento específico para XGBoost:\n",
    "- No requiere escalado\n",
    "- Label Encoding para categóricas\n",
    "- Target Encoding para 'course'\n",
    "\n",
    "Pipeline:\n",
    "1. Carga de datos preprocesados\n",
    "2. Definición de variables por fase temporal\n",
    "3. Split estratificado (80/20)\n",
    "4. Preprocesamiento específico para XGBoost\n",
    "5. Entrenamiento con Cross-Validation 5-fold\n",
    "6. Evaluación en test set\n",
    "7. Comparación de resultados por fase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-imports",
   "metadata": {},
   "source": [
    "## 0. Librerias y configuración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Preprocesamiento\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Modelo\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Métricas\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix, classification_report,\n",
    "    roc_curve, precision_recall_curve, average_precision_score\n",
    ")\n",
    "\n",
    "# Target Encoding\n",
    "from category_encoders import TargetEncoder\n",
    "\n",
    "# Configuración de visualización\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "\n",
    "# Seed para reproducibilidad\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# Directorio de salida\n",
    "OUTPUT_DIR = \"../outputs/figures/modelado/XGBoost/\"\n",
    "OUTPUT_DIR_REPORTES = \"../outputs/models/XGBoost/\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(OUTPUT_DIR_REPORTES, exist_ok=True)\n",
    "\n",
    "# mlflow\n",
    "import mlflow\n",
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-load",
   "metadata": {},
   "source": [
    "## 1. Carga de datos preprocesados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar dataset preprocesado\n",
    "df = pd.read_csv('../data/processed/preprocessed_data.csv')\n",
    "\n",
    "print(f\"Dataset cargado: {df.shape[0]} filas x {df.shape[1]} columnas\")\n",
    "print(df['target_binario'].value_counts())\n",
    "print(f\"\\nRatio de desbalance: {df['target_binario'].value_counts()[0] / df['target_binario'].value_counts()[1]:.2f}:1\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-variables",
   "metadata": {},
   "source": [
    "## 2. Definición de variables por fase temporal (T0, T1, T2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "define-variables",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TARGET\n",
    "TARGET = 'target_binario'\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# VARIABLES BINARIAS (no requieren encoding, ya son 0/1)\n",
    "# -----------------------------------------------------------------------------\n",
    "VARS_BINARIAS_T0 = [\n",
    "    'daytimeevening_attendance',\n",
    "    'displaced',\n",
    "    'educational_special_needs',\n",
    "    'gender',\n",
    "    'scholarship_holder',\n",
    "    'international',\n",
    "    'is_single'\n",
    "]\n",
    "\n",
    "VARS_BINARIAS_T1 = [\n",
    "    'debtor',\n",
    "    'tuition_fees_up_to_date'\n",
    "]\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# VARIABLES NUMÉRICAS (NO requieren escalado para XGBoost)\n",
    "# -----------------------------------------------------------------------------\n",
    "VARS_NUMERICAS_T0 = [\n",
    "    'age_at_enrollment',\n",
    "    'admission_grade',\n",
    "    'previous_qualification_grade'\n",
    "]\n",
    "\n",
    "VARS_NUMERICAS_T1 = [\n",
    "    'curricular_units_1st_sem_credited',\n",
    "    'curricular_units_1st_sem_enrolled',\n",
    "    'curricular_units_1st_sem_evaluations',\n",
    "    'curricular_units_1st_sem_approved',\n",
    "    'curricular_units_1st_sem_grade',\n",
    "    'curricular_units_1st_sem_without_evaluations',\n",
    "    'unemployment_rate',\n",
    "    'inflation_rate',\n",
    "    'gdp'\n",
    "]\n",
    "\n",
    "VARS_NUMERICAS_T2 = [\n",
    "    'curricular_units_2nd_sem_credited',\n",
    "    'curricular_units_2nd_sem_enrolled',\n",
    "    'curricular_units_2nd_sem_evaluations',\n",
    "    'curricular_units_2nd_sem_approved',\n",
    "    'curricular_units_2nd_sem_grade',\n",
    "    'curricular_units_2nd_sem_without_evaluations'\n",
    "]\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# VARIABLES CATEGÓRICAS AGRUPADAS (requieren Label Encoding para XGBoost)\n",
    "# -----------------------------------------------------------------------------\n",
    "VARS_CATEGORICAS_AGRUPADAS_T0 = [\n",
    "    'application_mode_risk',\n",
    "    'previous_qualification_risk',\n",
    "    'mothers_qualification_level',\n",
    "    'fathers_qualification_level',\n",
    "    'mothers_occupation_level',\n",
    "    'fathers_occupation_level'\n",
    "]\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# VARIABLES CATEGÓRICAS PARA TARGET ENCODING\n",
    "# -----------------------------------------------------------------------------\n",
    "VARS_TARGET_ENCODING_T0 = ['course']\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# VARIABLE ORDINAL (se trata como numérica)\n",
    "# -----------------------------------------------------------------------------\n",
    "VARS_ORDINALES_T0 = ['application_order']\n",
    "\n",
    "# =============================================================================\n",
    "# COMPOSICIÓN DE VARIABLES POR FASE TEMPORAL\n",
    "# =============================================================================\n",
    "\n",
    "# T0: Variables disponibles al momento de matrícula\n",
    "VARS_T0 = (\n",
    "    VARS_BINARIAS_T0 +\n",
    "    VARS_NUMERICAS_T0 +\n",
    "    VARS_CATEGORICAS_AGRUPADAS_T0 +\n",
    "    VARS_TARGET_ENCODING_T0 +\n",
    "    VARS_ORDINALES_T0\n",
    ")\n",
    "\n",
    "# T1: T0 + variables del 1er semestre\n",
    "VARS_T1 = (\n",
    "    VARS_T0 +\n",
    "    VARS_BINARIAS_T1 +\n",
    "    VARS_NUMERICAS_T1\n",
    ")\n",
    "\n",
    "# T2: T1 + variables del 2do semestre\n",
    "VARS_T2 = (\n",
    "    VARS_T1 +\n",
    "    VARS_NUMERICAS_T2\n",
    ")\n",
    "\n",
    "print(\"================================================================================\")\n",
    "print(\"  VARIABLES POR FASE TEMPORAL\")\n",
    "print(\"================================================================================\")\n",
    "print(f\"\\n T0 (Matrícula): {len(VARS_T0)} variables\")\n",
    "print(f\" T1 (Fin 1er Sem): {len(VARS_T1)} variables (+{len(VARS_T1) - len(VARS_T0)})\")\n",
    "print(f\" T2 (Fin 2do Sem): {len(VARS_T2)} variables (+{len(VARS_T2) - len(VARS_T1)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-split",
   "metadata": {},
   "source": [
    "## 3. Split TRAIN/TEST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-test-split",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split se hace en totalidad del dataste, posteriormente se seleccionan las variables según la fase temporal para entrenemiento y evaluaciónl\n",
    "\n",
    "X = df[VARS_T2].copy()\n",
    "y = df[TARGET].copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(\"================================================================================\")\n",
    "print(\"  SPLIT TRAIN/TEST\")\n",
    "print(\"================================================================================\")\n",
    "print(f\"\\nTrain: {X_train.shape[0]} ({X_train.shape[0]/len(df)*100:.1f}%)\")\n",
    "print(f\"Test:  {X_test.shape[0]} ({X_test.shape[0]/len(df)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nDistribución del target en Train:\")\n",
    "print(y_train.value_counts())\n",
    "print(f\"Ratio de desbalance:: {y_train.value_counts()[0] / y_train.value_counts()[1]:.2f}:1\")\n",
    "\n",
    "print(f\"\\nDistribución del target en Test:\")\n",
    "print(y_test.value_counts())\n",
    "print(f\"Ratio de desbalance:: {y_test.value_counts()[0] / y_test.value_counts()[1]:.2f}:1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-preprocessing",
   "metadata": {},
   "source": [
    "## 4. Funciones de preprocesamiento para XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preprocessing-functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtiene_variables_por_fase(fase):\n",
    "    # Retorna las listas de variables según la fase temporal, retorna diccionario con variables de la fase\n",
    "    if fase == 'T0':\n",
    "        return {\n",
    "            'binarias': VARS_BINARIAS_T0,\n",
    "            'numericas': VARS_NUMERICAS_T0 + VARS_ORDINALES_T0,\n",
    "            'categoricas_le': VARS_CATEGORICAS_AGRUPADAS_T0,\n",
    "            'categoricas_te': VARS_TARGET_ENCODING_T0,\n",
    "            'all': VARS_T0\n",
    "        }\n",
    "    elif fase == 'T1':\n",
    "        return {\n",
    "            'binarias': VARS_BINARIAS_T0 + VARS_BINARIAS_T1,\n",
    "            'numericas': VARS_NUMERICAS_T0 + VARS_ORDINALES_T0 + VARS_NUMERICAS_T1,\n",
    "            'categoricas_le': VARS_CATEGORICAS_AGRUPADAS_T0,\n",
    "            'categoricas_te': VARS_TARGET_ENCODING_T0,\n",
    "            'all': VARS_T1\n",
    "        }\n",
    "    elif fase == 'T2':\n",
    "        return {\n",
    "            'binarias': VARS_BINARIAS_T0 + VARS_BINARIAS_T1,\n",
    "            'numericas': VARS_NUMERICAS_T0 + VARS_ORDINALES_T0 + VARS_NUMERICAS_T1 + VARS_NUMERICAS_T2,\n",
    "            'categoricas_le': VARS_CATEGORICAS_AGRUPADAS_T0,\n",
    "            'categoricas_te': VARS_TARGET_ENCODING_T0,\n",
    "            'all': VARS_T2\n",
    "        }\n",
    "    else:\n",
    "        raise ValueError(f\"Fase no válida: {fase}. Usar 'T0', 'T1', o 'T2'\")\n",
    "\n",
    "\n",
    "def preprocesamiento_xgboost(X_train, X_test, y_train, fase):\n",
    "    # Preprocesa los datos para XGBoost    \n",
    "    variables_fase = obtiene_variables_por_fase(fase)\n",
    "    \n",
    "    # Seleccionar solo las variables de la fase\n",
    "    X_train_fase = X_train[variables_fase['all']].copy()\n",
    "    X_test_fase = X_test[variables_fase['all']].copy()\n",
    "    \n",
    "    # Diccionario para guardar encoders\n",
    "    label_encoders = {}\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # 1. TARGET ENCODING para 'course' \n",
    "    # -------------------------------------------------------------------------\n",
    "    te = TargetEncoder(cols=variables_fase['categoricas_te'], smoothing=0.3)\n",
    "    \n",
    "    for col in variables_fase['categoricas_te']:\n",
    "        X_train_fase[col + '_encoded'] = te.fit_transform(X_train_fase[[col]], y_train)[col]\n",
    "        X_test_fase[col + '_encoded'] = te.transform(X_test_fase[[col]])[col]\n",
    "        # Eliminar columna original\n",
    "        X_train_fase = X_train_fase.drop(columns=[col])\n",
    "        X_test_fase = X_test_fase.drop(columns=[col])\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # 2. LABEL ENCODING para categóricas agrupadas\n",
    "    # -------------------------------------------------------------------------\n",
    "    for col in variables_fase['categoricas_le']:\n",
    "        le = LabelEncoder()\n",
    "        X_train_fase[col] = le.fit_transform(X_train_fase[col].astype(str))\n",
    "        X_test_fase[col] = le.transform(X_test_fase[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # Guardar información\n",
    "    # -------------------------------------------------------------------------\n",
    "    variables = X_train_fase.columns.tolist()\n",
    "    preprocessors = {\n",
    "        'target_encoder': te,\n",
    "        'label_encoders': label_encoders,\n",
    "        'feature_names': variables\n",
    "    }\n",
    "    \n",
    "    return X_train_fase, X_test_fase, variables, preprocessors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-cv-functions",
   "metadata": {},
   "source": [
    "## 5. Funciones entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "training-functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrena_xgboost(X_train, y_train, fase, cv_folds=5):\n",
    "    \"\"\"Entrena y evalúa XGBoost con Cross-Validation.\"\"\"\n",
    "\n",
    "    mlflow.end_run()\n",
    "         \n",
    "    print(\"================================================================================\")\n",
    "    print(f\"  ENTRENAMIENTO XGBOOST - FASE {fase}\")\n",
    "    print(\"================================================================================\")\n",
    "    print(f\"\\nVariables: {X_train.shape[1]}\")\n",
    "    print(f\"Registros: {X_train.shape[0]}\")\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # Calcular scale_pos_weight para desbalance\n",
    "    # -------------------------------------------------------------------------\n",
    "    n_neg = (y_train == 0).sum()\n",
    "    n_pos = (y_train == 1).sum()\n",
    "    scale_pos_weight = n_neg / n_pos\n",
    "    print(f\"\\nscale_pos_weight: {scale_pos_weight:.2f}\")\n",
    "\n",
    "    print(f\"\\nHiperparámetros (por defecto):\")\n",
    "    print(f\"   • n_estimators: 100\")\n",
    "    print(f\"   • max_depth: 6\")\n",
    "    print(f\"   • learning_rate: 0.3\")\n",
    "    print(f\"   • subsample: 1.0\")\n",
    "    print(f\"   • colsample_bytree: 1.0\")\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # Cross-Validation con loop manual\n",
    "    # -------------------------------------------------------------------------\n",
    "    print(f\"\\nCross-Validation ({cv_folds}-fold):\")\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=RANDOM_STATE)\n",
    "    \n",
    "    # Almacenar resultados por fold\n",
    "    cv_results = {\n",
    "        'train_accuracy': [], 'test_accuracy': [],\n",
    "        'train_precision': [], 'test_precision': [],\n",
    "        'train_recall': [], 'test_recall': [],\n",
    "        'train_f1': [], 'test_f1': [],\n",
    "        'train_roc_auc': [], 'test_roc_auc': []\n",
    "    }\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(cv.split(X_train, y_train)):\n",
    "        X_fold_train = X_train.iloc[train_idx]\n",
    "        X_fold_val = X_train.iloc[val_idx]\n",
    "        y_fold_train = y_train.iloc[train_idx]\n",
    "        y_fold_val = y_train.iloc[val_idx]\n",
    "        \n",
    "        # Crear y entrenar modelo\n",
    "        model = XGBClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=6,\n",
    "            learning_rate=0.3,\n",
    "            subsample=1.0,\n",
    "            colsample_bytree=1.0,\n",
    "            min_child_weight=1,\n",
    "            gamma=0,\n",
    "            reg_alpha=0,\n",
    "            reg_lambda=1,\n",
    "            scale_pos_weight=scale_pos_weight,\n",
    "            objective='binary:logistic',\n",
    "            eval_metric='logloss',\n",
    "            use_label_encoder=False,\n",
    "            random_state=RANDOM_STATE,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        model.fit(X_fold_train, y_fold_train)\n",
    "        \n",
    "        # Predicciones\n",
    "        y_train_pred = model.predict(X_fold_train)\n",
    "        y_train_proba = model.predict_proba(X_fold_train)[:, 1]\n",
    "        y_val_pred = model.predict(X_fold_val)\n",
    "        y_val_proba = model.predict_proba(X_fold_val)[:, 1]\n",
    "        \n",
    "        # Métricas Train\n",
    "        cv_results['train_accuracy'].append(accuracy_score(y_fold_train, y_train_pred))\n",
    "        cv_results['train_precision'].append(precision_score(y_fold_train, y_train_pred))\n",
    "        cv_results['train_recall'].append(recall_score(y_fold_train, y_train_pred))\n",
    "        cv_results['train_f1'].append(f1_score(y_fold_train, y_train_pred))\n",
    "        cv_results['train_roc_auc'].append(roc_auc_score(y_fold_train, y_train_proba))\n",
    "        \n",
    "        # Métricas Validation\n",
    "        cv_results['test_accuracy'].append(accuracy_score(y_fold_val, y_val_pred))\n",
    "        cv_results['test_precision'].append(precision_score(y_fold_val, y_val_pred))\n",
    "        cv_results['test_recall'].append(recall_score(y_fold_val, y_val_pred))\n",
    "        cv_results['test_f1'].append(f1_score(y_fold_val, y_val_pred))\n",
    "        cv_results['test_roc_auc'].append(roc_auc_score(y_fold_val, y_val_proba))\n",
    "    \n",
    "    # Convertir a numpy arrays\n",
    "    for key in cv_results:\n",
    "        cv_results[key] = np.array(cv_results[key])\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # Resultados por fold\n",
    "    # -------------------------------------------------------------------------\n",
    "    print(\"\\n Resultados por fold:\")\n",
    "    for i in range(cv_folds):\n",
    "        print(f\"\\n  Fold {i+1}:\")\n",
    "        for metric in ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']:\n",
    "            train_score = cv_results[f'train_{metric}'][i]\n",
    "            val_score = cv_results[f'test_{metric}'][i]\n",
    "            print(f\"    {metric:<10} | Train: {train_score:.4f} | Val: {val_score:.4f}\")\n",
    "\n",
    "\n",
    "    mlflow.set_experiment(\"TFM_Dropout_Prediction\")\n",
    "    with mlflow.start_run(run_name=f\"XGBoost_CV5_{fase}\"):\n",
    "        mlflow.set_tag(\"modelo\", 'Params por default')\n",
    "        mlflow.set_tag(\"tipo\", 'Validacion cruzada')\n",
    "        mlflow.log_params(model.get_params())\n",
    "\n",
    "        # -------------------------------------------------------------------------\n",
    "        # Resumen CV (media ± std)\n",
    "        # -------------------------------------------------------------------------\n",
    "        print(f\"\\n Resumen Cross-Validation:\")\n",
    "        print(f\"\\n   {'Métrica':<12} {'Train Mean':>12} {'Train Std':>12} {'Val Mean':>12} {'Val Std':>12}\")\n",
    "        print(f\"   {'-'*60}\")\n",
    "        for metric in ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']:\n",
    "            train_mean = cv_results[f'train_{metric}'].mean()\n",
    "            train_std = cv_results[f'train_{metric}'].std()\n",
    "            val_mean = cv_results[f'test_{metric}'].mean()\n",
    "            val_std = cv_results[f'test_{metric}'].std()\n",
    "            # mlflow\n",
    "            mlflow.log_metric(f'test_{metric}_mean', val_mean.round(4))\n",
    "            mlflow.log_metric(f'test_{metric}_std', val_std.round(4))\n",
    "            print(f\"   {metric:<12} {train_mean:>12.4f} {train_std:>12.4f} {val_mean:>12.4f} {val_std:>12.4f}\")\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # Entrenar modelo final en todo el train set\n",
    "    # -------------------------------------------------------------------------\n",
    "    model_final = XGBClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.3,\n",
    "        subsample=1.0,\n",
    "        colsample_bytree=1.0,\n",
    "        min_child_weight=1,\n",
    "        gamma=0,\n",
    "        reg_alpha=0,\n",
    "        reg_lambda=1,\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        objective='binary:logistic',\n",
    "        eval_metric='logloss',\n",
    "        use_label_encoder=False,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    model_final.fit(X_train, y_train)\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # Retornar resultados\n",
    "    # -------------------------------------------------------------------------\n",
    "    results = {\n",
    "        'phase': fase,\n",
    "        'model': model_final,\n",
    "        'n_features': X_train.shape[1],\n",
    "        'cv_results': cv_results,\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "def resumen_cv(cv_results, fase, modelo):\n",
    "    metrics = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "\n",
    "    summary = {\n",
    "        'modelo': modelo,\n",
    "        'fase': fase\n",
    "    }\n",
    "\n",
    "\n",
    "    # -------------------------\n",
    "    # Métricas de VALIDACIÓN\n",
    "    # -------------------------\n",
    "    for metric in metrics:\n",
    "        summary[f'{metric}_val_mean'] = cv_results[f'test_{metric}'].mean()\n",
    "        summary[f'{metric}_val_std']  = cv_results[f'test_{metric}'].std()\n",
    "        \n",
    "\n",
    "    # -------------------------\n",
    "    # Métricas de TRAIN\n",
    "    # -------------------------\n",
    "    for metric in metrics:\n",
    "        summary[f'{metric}_train_mean'] = cv_results[f'train_{metric}'].mean()\n",
    "        summary[f'{metric}_train_std']  = cv_results[f'train_{metric}'].std()\n",
    "\n",
    "\n",
    "    return pd.DataFrame([summary])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-t0",
   "metadata": {},
   "source": [
    "## 6. Modelado FASE T0 (MATRÍCULA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model-t0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocesamiento para T0\n",
    "X_train_T0, X_test_T0, features_T0, prep_T0 = preprocesamiento_xgboost(\n",
    "    X_train, X_test, y_train, fase='T0'\n",
    ")\n",
    "\n",
    "print(f\"\\nT0 - Dimensiones después del preprocesamiento:\")\n",
    "print(f\"   Train: {X_train_T0.shape}\")\n",
    "print(f\"   Test:  {X_test_T0.shape}\")\n",
    "print(f\"   Variables: {len(features_T0)}\")\n",
    "print(f\"   \\nLas variables son:\")\n",
    "X_train_T0.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-t0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar y evaluar T0\n",
    "results_T0 = entrena_xgboost(X_train_T0, y_train, fase='T0')\n",
    "\n",
    "df_resumen_xgboost = resumen_cv(\n",
    "    cv_results=results_T0['cv_results'],\n",
    "    fase='T0',\n",
    "    modelo='XGBoost'\n",
    ")\n",
    "# Guardar tabla de comparación\n",
    "df_resumen_xgboost.to_csv(f\"{OUTPUT_DIR_REPORTES}cv_summary_XGBoost.csv\", index=False)\n",
    "\n",
    "print(f\"Resultados guardados en: {OUTPUT_DIR_REPORTES}cv_summary_XGBoost.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34984a5",
   "metadata": {},
   "source": [
    "### Comentarios FASE 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa00e7f3",
   "metadata": {},
   "source": [
    "1. Se observa que todas las métricas en entrenamiento alcanzan casi el valor máximo (1.0) lo que indica sobreentrenamiento fuerte, aunque ligeramente menor en comparación con RF en Fase 0. El recall en validación es 0.5445, inferior RL.\n",
    "2. Las métricas de validación caen de forma relevente, en proemdio 0.2276, en consecuencia, no generaliza adecuadamente y desviación standard presentan mayor variación (promedio 0.0201)\n",
    "3. XGBoost no aporta ventaja en fase T0 y presenta sobreajuste."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-t1",
   "metadata": {},
   "source": [
    "## 7. Modelado FASE T1 (FIN 1ER SEMESTRE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model-t1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocesamiento para T1\n",
    "X_train_T1, X_test_T1, features_T1, prep_T1 = preprocesamiento_xgboost(\n",
    "    X_train, X_test, y_train, fase='T1'\n",
    ")\n",
    "\n",
    "print(f\"\\nT1 - Dimensiones después del preprocesamiento:\")\n",
    "print(f\"   Train: {X_train_T1.shape}\")\n",
    "print(f\"   Test:  {X_test_T1.shape}\")\n",
    "print(f\"   Features: {len(features_T1)}\")\n",
    "print(f\"   \\nLas variables son:\")\n",
    "X_train_T1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-t1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar y evaluar T1\n",
    "results_T1 = entrena_xgboost(X_train_T1, y_train, fase='T1')\n",
    "\n",
    "df_resumen_XGBoost_T1 = resumen_cv(\n",
    "    cv_results=results_T1['cv_results'],\n",
    "    fase='T1',\n",
    "    modelo='XGBoost'\n",
    ")\n",
    "\n",
    "xg_path = \"../outputs/models/XGBoost/cv_summary_XGBoost.csv\"\n",
    "df_xg = pd.read_csv(xg_path)\n",
    "df_final = pd.concat([df_xg, df_resumen_XGBoost_T1], ignore_index=True)\n",
    "\n",
    "# Guardar tabla de comparación\n",
    "df_final.to_csv(xg_path, index=False)\n",
    "print(f\"\\nResultados guardados en: {OUTPUT_DIR_REPORTES}cv_summary_XGBoost.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4da3a7",
   "metadata": {},
   "source": [
    "### Comentarios FASE 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fb6b83",
   "metadata": {},
   "source": [
    "1. Se observa que casi la totalidad de las métricas en entrenamiento alcanzan el valor máximo (1.0) lo que indica sobreentrenamiento severo. El recall en validación es 0.7071, similar a RL y RF.\n",
    "2. Las métricas de validación caen de forma relevente, en promedio 0.12, en consecuencia, no generaliza adecuadamente. Desviación standard presentan menor variación (promedio 0.0138) que la Fase 0 presentando una estabilidad relativa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-t2",
   "metadata": {},
   "source": [
    "## 8. Modelado FASE T2 (FIN 2DO SEMESTRE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model-t2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocesamiento para T2\n",
    "X_train_T2, X_test_T2, features_T2, prep_T2 = preprocesamiento_xgboost(\n",
    "    X_train, X_test, y_train, fase='T2'\n",
    ")\n",
    "\n",
    "print(f\"\\nT2 - Dimensiones después del preprocesamiento:\")\n",
    "print(f\"   Train: {X_train_T2.shape}\")\n",
    "print(f\"   Test:  {X_test_T2.shape}\")\n",
    "print(f\"   Features: {len(features_T2)}\")\n",
    "print(f\"   \\nLas variables son:\")\n",
    "X_train_T2.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-t2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar y evaluar T2\n",
    "results_T2 = entrena_xgboost(X_train_T2, y_train, fase='T2')\n",
    "\n",
    "df_resumen_XGBoost_T2 = resumen_cv(\n",
    "    cv_results=results_T2['cv_results'],\n",
    "    fase='T2',\n",
    "    modelo='XGBoost'\n",
    ")\n",
    "\n",
    "xg_path = \"../outputs/models/XGBoost/cv_summary_XGBoost.csv\"\n",
    "df_xg = pd.read_csv(xg_path)\n",
    "df_final = pd.concat([df_xg, df_resumen_XGBoost_T2], ignore_index=True)\n",
    "\n",
    "# Guardar tabla de comparación\n",
    "df_final.to_csv(xg_path, index=False)\n",
    "print(f\"\\nResultados guardados en: {OUTPUT_DIR_REPORTES}cv_summary_XGBoost.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3e2930",
   "metadata": {},
   "source": [
    "### Comentarios FASE 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db75faa7",
   "metadata": {},
   "source": [
    "1. Continua presentando las métricas en entrenamiento con valor máximo (1.0) lo que indica sobreentrenamiento severo. El recall en validación es 0.7485 y un AUC 0.9080, reflejando mayor capacidad predictiva.\n",
    "2. Las métricas de validación caen de forma relevente, en promedio 0.2544, en consecuencia, no generaliza adecuadamente.  Desviación standard presentan mayor variación (promedio 0.0162) mejor que la fase 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba5f5a1",
   "metadata": {},
   "source": [
    "## 9. Resumen Final XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758bf057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar resumen final\n",
    "df_final = pd.read_csv(f\"{OUTPUT_DIR_REPORTES}cv_summary_XGBoost.csv\")\n",
    "\n",
    "print(\"================================================================================\")\n",
    "print(\"  RESUMEN XGBoost - CROSS VALIDATION\")\n",
    "print(\"================================================================================\")\n",
    "print(df_final.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb48f15",
   "metadata": {},
   "source": [
    "## 10. Resumen completo de entrenamiento (Todos los algoritmos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bcf9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "resumen_path = \"../outputs/models/cv_summary_entrenamiento.csv\"\n",
    "df_resumen = pd.read_csv(resumen_path)\n",
    "\n",
    "xg_path = \"../outputs/models/XGBoost/cv_summary_XGBoost.csv\"\n",
    "df_xg = pd.read_csv(xg_path)\n",
    "\n",
    "df_resumen = pd.concat([df_resumen, df_xg], ignore_index=True)\n",
    "\n",
    "# Guardar tabla de comparación\n",
    "df_resumen.to_csv(f\"../outputs/models/cv_summary_entrenamiento.csv\", index=False)\n",
    "\n",
    "print(f\"Resultados guardados en: ../outputs/models/cv_summary_entrenamiento.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aeb4343",
   "metadata": {},
   "source": [
    "## Conclusión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621dbaa8",
   "metadata": {},
   "source": [
    "Aunque XGBoost presenta desviaciones standard moderadas mas altas que RL y similares a RF, estan se disminuyen en la medida que se agrega más información. En comparación con RF presenta mejor recall, AUC y menor varianza, sin emabargo, al comparar con RL, este algoritmo presenta menor capacidad de detectar a los estudiantes desertores y menor capacidad de discriminación. Si bien presenta una mejora relevante al incoporar información académica en las fases 1 y 2, presenta un sobreaprendizaje en el conjunto de entrenamiento, lo cual sugiere la necesidad de una optmización adecuada de los los hiperparámetros."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFM_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
